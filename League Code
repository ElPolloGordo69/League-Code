import gradio as gr
import pandas as pd
import numpy as np
import os
import tempfile
from fuzzywuzzy import process
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist

def filter_problematic_players(df):
    """Remove players with common names that cause issues"""
    if df is None or len(df) == 0 or 'Name' not in df.columns:
        return df
        
    # Create a copy to avoid modifying the original
    filtered_df = df.copy()
    
    # Define exact problematic name combinations (more specific)
    problematic_names = [
        "jose ramirez", "josé ramirez", "jose ramírez", "josé ramírez",
        "julio rodriguez", "julio rodríguez",
        "will smith",
        "luis garcia", "luis garcía", 
        "luis castillo"
    ]
    
    # Filter out exact name matches (case insensitive)
    for name in problematic_names:
        filtered_df = filtered_df[~filtered_df['Name'].str.lower().str.strip().eq(name)]
    
    # Remove duplicates by Name
    filtered_df = filtered_df.drop_duplicates(subset=['Name'])
    
    return filtered_df

def analyze_standings(standings_file, my_team_name):
    """
    Analyze standings to find opportunity clusters and create category weights
    """
    # Load standings
    try:
        standings = pd.read_csv(standings_file)
    except Exception as e:
        print(f"Error loading standings file: {str(e)}")
        return None
    
    # Make sure we have a team column
    team_col = next((c for c in standings.columns if c.lower() in ['team', 'team name', 'name', 'teamname']), None)
    if not team_col:
        print("No team name column found in standings")
        return None
    
    # Find my team's position in each category
    my_team = standings[standings[team_col] == my_team_name]
    if len(my_team) == 0:
        print(f"Team '{my_team_name}' not found in standings")
        return None
    
    # Get statistical categories (excluding team name, total points, etc.)
    stat_cols = [col for col in standings.columns 
                if standings[col].dtype in [np.float64, np.int64] 
                and col.lower() not in ['rank', 'total', 'points', 'totalpoints', 'total_points']]
    
    if not stat_cols:
        print("No statistical categories found in standings")
        return None
    
    # Calculate weights for each category
    weights = {}
    num_teams = len(standings)
    
    for cat in stat_cols:
        # Sort standings by this category
        cat_standings = standings.sort_values(by=cat, ascending=False)
        
        # Find my team's position (1-indexed)
        my_position = cat_standings[cat_standings[team_col] == my_team_name].index[0] + 1
        
        # Calculate base weight based on position
        normalized_position = my_position / num_teams
        position_weight = 1.0 - 4.0 * (normalized_position - 0.5)**2
        
        # Find clusters in this category
        values = cat_standings[cat].values.reshape(-1, 1)
        
        # Skip if all values are the same
        if np.std(values) == 0:
            weights[cat] = 0.5
            continue
        
        # Calculate distances and perform hierarchical clustering
        distances = pdist(values)
        if len(distances) == 0:
            weights[cat] = 0.5
            continue
            
        Z = linkage(distances, method='ward')
        
        # Determine appropriate number of clusters
        num_clusters = min(5, max(3, int(num_teams / 3)))
        
        # Get cluster assignments
        clusters = fcluster(Z, num_clusters, criterion='maxclust')
        
        # Find which cluster my team is in
        my_cluster = clusters[my_position - 1]
        
        # Count teams in my cluster and adjacent clusters
        my_cluster_size = np.sum(clusters == my_cluster)
        
        # Teams in adjacent positions
        adjacent_positions = 2
        adjacent_teams = sum(1 for i in range(max(0, my_position-adjacent_positions-1), 
                                            min(num_teams, my_position+adjacent_positions)))
        
        # Cluster density weight
        cluster_weight = my_cluster_size / num_teams * 2.0
        
        # Adjacent position weight
        adjacent_weight = adjacent_teams / num_teams * 1.5
        
        # Combine weights
        weights[cat] = position_weight * 0.4 + cluster_weight * 0.4 + adjacent_weight * 0.2
        
    # Normalize weights
    total_weight = sum(weights.values())
    if total_weight > 0:
        weights = {cat: weight * len(weights) / total_weight for cat, weight in weights.items()}
    
    return weights

def calculate_mash_score(df, category_weights, is_pitcher=False):
    """
    Calculate MASH score based on weighted Z-scores and standings opportunity
    """
    if df is None or len(df) == 0 or not category_weights:
        return df
        
    # Create a copy to avoid modifying the original
    df_mash = df.copy()
    
    # Map fantasy categories to projection categories
    category_map = {
        # Hitting categories
        'AVG': 'AVG', 'BA': 'AVG',
        'HR': 'HR', 'HOME RUNS': 'HR',
        'R': 'R', 'RUNS': 'R',
        'RBI': 'RBI', 'RUNS BATTED IN': 'RBI',
        'SB': 'SB', 'STOLEN BASES': 'SB',
        'OPS': 'OPS', 'ON BASE PLUS SLUGGING': 'OPS',
        
        # Pitching categories
        'ERA': 'ERA', 'EARNED RUN AVERAGE': 'ERA',
        'WHIP': 'WHIP',
        'W': 'W', 'WINS': 'W',
        'SV': 'SV', 'SAVES': 'SV',
        'K': 'K', 'SO': 'K', 'STRIKEOUTS': 'K',
        'QS': 'QS', 'QUALITY STARTS': 'QS',
        'HLD': 'HLD', 'HOLDS': 'HLD'
    }
    
    # Find Z-score columns
    z_columns = [col for col in df_mash.columns if col.endswith('_z')]
    if not z_columns:
        print("No Z-score columns found")
        return df_mash
        
    # Calculate weighted Z-scores for MASH
    mash_components = []
    
    for z_col in z_columns:
        # Extract the base category name
        base_category = z_col[:-2]
        
        # Find if this category has a weight
        weight = None
        for stand_cat, proj_cat in category_map.items():
            if stand_cat.upper() in category_weights and proj_cat.upper() == base_category.upper():
                weight = category_weights[stand_cat.upper()]
                break
        
        # If no weight found, use 1.0
        if weight is None:
            weight = 1.0
            
        # Create weighted Z-score column
        weighted_col = f"{base_category}_mash"
        df_mash[weighted_col] = df_mash[z_col] * weight
        mash_components.append(weighted_col)
    
    # Calculate MASH score
    if mash_components:
        df_mash['MASH'] = df_mash[mash_components].sum(axis=1)
        
        # Reorder columns
        cols = list(df_mash.columns)
        cols.remove('MASH')
        
        name_idx = cols.index('Name') if 'Name' in cols else -1
        total_z_idx = cols.index('Total_Z') if 'Total_Z' in cols else -1
        
        if total_z_idx >= 0:
            cols.insert(total_z_idx + 1, 'MASH')
        else:
            cols.insert(name_idx + 1, 'MASH') if name_idx >= 0 else cols.insert(0, 'MASH')
        
        df_mash = df_mash[cols]
        
    return df_mash

def calculate_mash_score_alt(df, category_weights, is_pitcher=False):
    """
    Calculate MASH score based on weighted Z-scores and standings opportunity
    Adapted for alternative league settings
    """
    if df is None or len(df) == 0 or not category_weights:
        return df
        
    # Create a copy to avoid modifying the original
    df_mash = df.copy()
    
    # Map fantasy categories to projection categories
    category_map = {
        # MODIFIED: New hitting categories
        'HR': 'HR', 'HOME RUNS': 'HR',
        'BB': 'BB', 'WALKS': 'BB',
        'SBN': 'SBN', 'NET STOLEN BASES': 'SBN', 'SB-CS': 'SBN',
        'OBP': 'OBP', 'ON BASE PERCENTAGE': 'OBP',
        'SLG': 'SLG', 'SLUGGING': 'SLG',
        
        # MODIFIED: New pitching categories
        'K/9': 'K/9', 'STRIKEOUTS PER 9': 'K/9',
        'K/BB': 'K/BB', 'STRIKEOUT TO WALK': 'K/BB',
        'ERA': 'ERA', 'EARNED RUN AVERAGE': 'ERA',
        'HR/9': 'HR/9', 'HOME RUNS PER 9': 'HR/9',
        'WHIP': 'WHIP'
    }
    
    # Find Z-score columns
    z_columns = [col for col in df_mash.columns if col.endswith('_z')]
    if not z_columns:
        print("No Z-score columns found")
        return df_mash
        
    # Calculate weighted Z-scores for MASH
    mash_components = []
    
    for z_col in z_columns:
        # Extract the base category name
        base_category = z_col[:-2]
        
        # Find if this category has a weight
        weight = None
        for stand_cat, proj_cat in category_map.items():
            if stand_cat.upper() in category_weights and proj_cat.upper() == base_category.upper():
                weight = category_weights[stand_cat.upper()]
                break
        
        # If no weight found, use 1.0
        if weight is None:
            weight = 1.0
            
        # Create weighted Z-score column
        weighted_col = f"{base_category}_mash"
        df_mash[weighted_col] = df_mash[z_col] * weight
        mash_components.append(weighted_col)
    
    # Calculate MASH score
    if mash_components:
        df_mash['MASH'] = df_mash[mash_components].sum(axis=1)
        
        # Reorder columns
        cols = list(df_mash.columns)
        cols.remove('MASH')
        
        name_idx = cols.index('Name') if 'Name' in cols else -1
        total_z_idx = cols.index('Total_Z') if 'Total_Z' in cols else -1
        
        if total_z_idx >= 0:
            cols.insert(total_z_idx + 1, 'MASH')
        else:
            cols.insert(name_idx + 1, 'MASH') if name_idx >= 0 else cols.insert(0, 'MASH')
        
        df_mash = df_mash[cols]
        
    return df_mash

def load_and_aggregate_ros():
    # Load all CSVs from repo
    atc = pd.read_csv('ATC.csv')
    oopsy = pd.read_csv('Oopsy.csv')
    bat_x = pd.read_csv('The Bat X.csv')
    atc_p = pd.read_csv('ATC PItching.csv')
    oopsy_p = pd.read_csv('Oopsy Pitching.csv')
    bat_p = pd.read_csv('The Bat Pitching.csv')
    profiles = pd.read_csv('Combined_Sorted_Profiles.csv')
    botstf = pd.read_csv('BotStf.csv')
    location = pd.read_csv('Location+.csv')
    idmap = pd.read_csv('SFBB Player ID Map - PLAYERIDMAP(1).csv')

    # Normalize IDs
    for df in [atc, oopsy, bat_x, atc_p, oopsy_p, bat_p, botstf, location, idmap]:
        if 'PlayerId' in df.columns:
            df['IDFANGRAPHS'] = df['PlayerId'].astype(str)
        if 'IDFANGRAPHS' in df.columns:
            df['IDFANGRAPHS'] = df['IDFANGRAPHS'].astype(str)
    if 'IDFANGRAPHS' in idmap.columns:
        idmap['IDFANGRAPHS'] = idmap['IDFANGRAPHS'].astype(str)

    # Normalize hitters to 600 PA
    for df in [atc, oopsy, bat_x]:
        if 'PA' in df.columns:
            for stat in ['AB', 'H', '2B', '3B', 'HR', 'R', 'RBI', 'BB', 'SO', 'SB', 'CS']:
                if stat in df.columns:
                    df[stat] = df.apply(lambda row: row[stat] * 600 / row['PA'] if row['PA'] > 0 else row[stat], axis=1)
    # Normalize pitchers to 180 IP
    for df in [atc_p, oopsy_p, bat_p]:
        if 'IP' in df.columns:
            for stat in ['W', 'L', 'SV', 'HLD', 'H', 'ER', 'HR', 'BB', 'SO']:
                if stat in df.columns:
                    df[stat] = df.apply(lambda row: row[stat] * 180 / row['IP'] if row['IP'] > 0 else row[stat], axis=1)

    # Aggregate hitters
    hitter_dfs = []
    for name, df in [('ATC', atc), ('Oopsy', oopsy), ('The Bat X', bat_x)]:
        df_ = df.copy()
        df_['System'] = name
        df_ = df_.rename(columns={"Name":"Name", "Team":"Team"})
        cols = ['Name', 'Team', 'IDFANGRAPHS'] + [c for c in df_.columns if df_[c].dtype in [np.float64, np.int64]]
        cols = [c for c in cols if c in df_.columns]
        hitter_dfs.append(df_[cols])
    all_hitters = pd.concat(hitter_dfs, ignore_index=True)
    numeric_cols = all_hitters.select_dtypes(include=[np.number]).columns
    agg_hitters = all_hitters.groupby(['Name', 'Team', 'IDFANGRAPHS'], dropna=False).agg({col:'mean' for col in numeric_cols})
    agg_hitters = agg_hitters.reset_index()

    # Add SEAGER and 90th Pctile EV
    seager_col = next((c for c in profiles.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in profiles.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    if seager_col and ev_col:
        profile_dict = {f"{row['Name']} {row['Team']}": (row[seager_col], row[ev_col]) for _, row in profiles.iterrows()}
        seager_avg = profiles[seager_col].mean()
        ev_avg = profiles[ev_col].mean()
        def get_feats(row):
            key = f"{row['Name']} {row['Team']}"
            if key in profile_dict:
                return profile_dict[key]
            match = process.extractOne(key, profile_dict.keys())
            if match and match[1] >= 85:
                return profile_dict[match[0]]
            return (seager_avg, ev_avg)
        agg_hitters[[seager_col, ev_col]] = agg_hitters.apply(lambda row: pd.Series(get_feats(row)), axis=1)

    # Aggregate pitchers
    pitcher_dfs = []
    for name, df in [('ATC', atc_p), ('Oopsy', oopsy_p), ('The Bat', bat_p)]:
        df_ = df.copy()
        df_['System'] = name
        df_ = df_.rename(columns={"Name":"Name", "Team":"Team"})
        cols = ['Name', 'Team', 'IDFANGRAPHS'] + [c for c in df_.columns if df_[c].dtype in [np.float64, np.int64]]
        cols = [c for c in cols if c in df_.columns]
        pitcher_dfs.append(df_[cols])
    all_pitchers = pd.concat(pitcher_dfs, ignore_index=True)
    numeric_cols = all_pitchers.select_dtypes(include=[np.number]).columns
    agg_pitchers = all_pitchers.groupby(['Name', 'Team', 'IDFANGRAPHS'], dropna=False).agg({col:'mean' for col in numeric_cols})
    agg_pitchers = agg_pitchers.reset_index()

    # Add BotStf and Location+
    if 'IDFANGRAPHS' in botstf.columns and 'botStf' in botstf.columns:
        agg_pitchers = agg_pitchers.merge(botstf[['IDFANGRAPHS', 'botStf']], on='IDFANGRAPHS', how='left')
    if 'IDFANGRAPHS' in location.columns and 'Location+' in location.columns:
        agg_pitchers = agg_pitchers.merge(location[['IDFANGRAPHS', 'Location+']], on='IDFANGRAPHS', how='left')
    if 'IDFANGRAPHS' in agg_hitters.columns and 'IDFANGRAPHS' in idmap.columns:
        agg_hitters = agg_hitters.merge(idmap, on='IDFANGRAPHS', how='left')
    if 'IDFANGRAPHS' in agg_pitchers.columns and 'IDFANGRAPHS' in idmap.columns:
        agg_pitchers = agg_pitchers.merge(idmap, on='IDFANGRAPHS', how='left')

    # Filter out problematic players
    agg_hitters = filter_problematic_players(agg_hitters)
    agg_pitchers = filter_problematic_players(agg_pitchers)
    
    # Calculate additional advanced stats for alt league
    # SBN (Net Stolen Bases)
    if 'SB' in agg_hitters.columns and 'CS' in agg_hitters.columns:
        agg_hitters['SBN'] = agg_hitters['SB'] - agg_hitters['CS']
    elif 'SB' in agg_hitters.columns:
        agg_hitters['SBN'] = agg_hitters['SB']
        
    # K/9 (Strikeouts per 9 innings)
    if 'K' in agg_pitchers.columns and 'IP' in agg_pitchers.columns:
        agg_pitchers['K/9'] = 9.0 * agg_pitchers['K'] / agg_pitchers['IP']
        
    # K/BB (Strikeout to Walk ratio)
    if 'K' in agg_pitchers.columns and 'BB' in agg_pitchers.columns:
        agg_pitchers['K/BB'] = agg_pitchers['K'] / agg_pitchers['BB'].replace(0, 0.01)
        
    # HR/9 (Home Runs per 9 innings)
    if 'HR' in agg_pitchers.columns and 'IP' in agg_pitchers.columns:
        agg_pitchers['HR/9'] = 9.0 * agg_pitchers['HR'] / agg_pitchers['IP']
    
    return agg_hitters, agg_pitchers

def find_matching_columns(df1, df2):
    """Find matching column pairs between two dataframes for player ID matching"""
    matches = []
    # Common player ID columns to check
    id_columns = ["IDFANGRAPHS", "PlayerId", "playerid", "MLBID", "MLBAMID", 
                  "ESPNID", "CBSID", "YAHOOID", "FANTRAXID", "OTTONEU_ID"]
    
    # Name columns to check
    name_columns = ["Name", "PLAYERNAME", "LASTNAME", "FANGRAPHSNAME", "Player"]
    
    # First check if there are exact ID column matches
    for col1 in df1.columns:
        for match in id_columns:
            if match.upper() == col1.upper():
                for col2 in df2.columns:
                    if match.upper() == col2.upper():
                        matches.append((col1, col2))
    
    # If no ID matches, try name columns
    if not matches:
        for col1 in df1.columns:
            for match in name_columns:
                if match.upper() == col1.upper():
                    for col2 in df2.columns:
                        if match.upper() == col2.upper():
                            matches.append((col1, col2))
                            
    # If still no matches, try cross-mapping common combinations
    if not matches:
        cross_maps = [
            ("PLAYERNAME", "Player"),
            ("Name", "Player"),
            ("FANTRAXID", "ID"),
            ("FANTRAXNAME", "Player"),
            ("IDFANGRAPHS", "ID")
        ]
        for col1, col2 in cross_maps:
            if col1 in df1.columns and col2 in df2.columns:
                matches.append((col1, col2))
    
    return matches

def filter_players(projections_df, league_df, status_values):
    """Filter projections to only players with specified status values"""
    status_col = next((c for c in league_df.columns if c.lower() == "status"), None)
    if not status_col:
        return None, "No 'Status' column found in league file."
    
    if not status_values:  # For lineup optimizer with no specific status filter
        filtered_league = league_df
    else:
        filtered_league = league_df[league_df[status_col].astype(str).str.upper().isin([s.upper() for s in status_values])]
    
    # Find matching columns between the two dataframes
    matches = find_matching_columns(projections_df, filtered_league)
    
    if not matches:
        return None, (
            f"No common player identifier found. "
            f"Projection columns: {projections_df.columns.tolist()[:10]}... | "
            f"League file columns: {filtered_league.columns.tolist()[:10]}..."
        )
    
    # Try each match pair until we get results
    for proj_col, league_col in matches:
        filtered_proj = pd.merge(
            projections_df, 
            filtered_league, 
            left_on=proj_col, 
            right_on=league_col, 
            how='inner'
        )
        if len(filtered_proj) > 0:
            # Add the status column to the filtered projections
            filtered_proj['Status'] = filtered_proj[status_col]
            # Remove duplicates by Name
            name_col = next((c for c in filtered_proj.columns if c.lower() == 'name'), None)
            if name_col:
                filtered_proj = filtered_proj.drop_duplicates(subset=[name_col])
            return filtered_proj, None
    
    return None, f"No players found with status {', '.join(status_values) if status_values else 'any'}"

def calculate_zscores_hitters(df, reference_df=None, top_n=300):
    """
    Calculate Z-scores for hitter categories and add total Z-score
    Uses a reference dataset or top_n players for calculating mean and std
    """
    if df is None or len(df) == 0:
        return df
    
    # Define categories and weights
    hitting_cats = {
        'R': {'higher_better': True, 'weight': 1.0},
        'HR': {'higher_better': True, 'weight': 1.0},
        'RBI': {'higher_better': True, 'weight': 1.0},
        'SB': {'higher_better': True, 'weight': 1.0},
        'AVG': {'higher_better': True, 'weight': 1.0},
        'OPS': {'higher_better': True, 'weight': 1.0}
    }
    
    # Find supplemental stats
    seager_col = next((c for c in df.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in df.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    
    if seager_col:
        hitting_cats[seager_col] = {'higher_better': True, 'weight': 0.25}
    if ev_col:
        hitting_cats[ev_col] = {'higher_better': True, 'weight': 0.25}
    
    # Create a copy
    df_z = df.copy()
    
    # If no reference dataframe is provided, use the input dataframe
    if reference_df is None:
        reference_df = df.copy()
    
    # Fill missing values with category averages before Z-score calculations
    for cat in hitting_cats:
        if cat in df_z.columns and df_z[cat].isna().any():
            category_mean = reference_df[cat].mean() if cat in reference_df.columns else df_z[cat].mean()
            # Add small random variation (±1%) to avoid identical values for missing data
            import random
            df_z[cat] = df_z[cat].apply(
                lambda x: category_mean * (1 + random.uniform(-0.01, 0.01)) if pd.isna(x) else x
            )
    
    # Filter out bottom performers 
    # Keep only top 80% of players for reference calculations to avoid skewing
    if len(reference_df) > top_n*1.2:  # Only if we have sufficient data
        category_references = {}
        for cat in hitting_cats:
            if cat in reference_df.columns:
                # Sort by category value
                is_higher_better = hitting_cats[cat]['higher_better']
                sorted_ref = reference_df.sort_values(cat, ascending=not is_higher_better)
                # Take top N rows and exclude bottom 20%
                cut_off = int(min(top_n, len(sorted_ref) * 0.8))
                category_references[cat] = sorted_ref.head(cut_off)
    else:
        # Use the whole reference dataset for all categories
        category_references = {cat: reference_df for cat in hitting_cats if cat in reference_df.columns}
    
    # Calculate z-scores for each category
    z_columns = []
    for cat, props in hitting_cats.items():
        if cat in df.columns and cat in category_references:
            # Skip if column is all NaN
            if df[cat].isna().all() or category_references[cat][cat].isna().all():
                continue
                
            col_z = f"{cat}_z"
            mean = category_references[cat][cat].mean()
            std = category_references[cat][cat].std()
            
            # Avoid division by zero
            if std == 0:
                df_z[col_z] = 0
            else:
                # Calculate z-score based on higher/lower better
                if props['higher_better']:
                    df_z[col_z] = (df[cat] - mean) / std
                else:
                    df_z[col_z] = (mean - df[cat]) / std
                
                # Cap z-scores at +/- 1.5
                df_z[col_z] = df_z[col_z].clip(-1.5, 1.5)
                    
                # Apply category weight
                df_z[col_z] = df_z[col_z] * props['weight']
            
            z_columns.append(col_z)
    
    # Calculate total z-score
    if z_columns:
        df_z['Total_Z'] = df_z[z_columns].sum(axis=1)
        
        # Reorder columns
        cols = list(df_z.columns)
        name_idx = cols.index('Name') if 'Name' in cols else -1
        if name_idx >= 0:
            cols.remove('Total_Z')
            cols.insert(name_idx + 1, 'Total_Z')
            df_z = df_z[cols]
    
    return df_z

def calculate_zscores_hitters_alt(df, reference_df=None, top_n=300):
    """
    Calculate Z-scores for hitter categories and add total Z-score
    Uses a reference dataset or top_n players for calculating mean and std
    Adapted for HR, BB, SBN, OBP, SLG categories
    """
    if df is None or len(df) == 0:
        return df
    
    # Define categories and weights - MODIFIED FOR NEW LEAGUE
    hitting_cats = {
        'HR': {'higher_better': True, 'weight': 1.0},
        'BB': {'higher_better': True, 'weight': 1.0},
        'SBN': {'higher_better': True, 'weight': 1.0},
        'OBP': {'higher_better': True, 'weight': 1.0},
        'SLG': {'higher_better': True, 'weight': 1.0}
    }
    
    # Find supplemental stats (still useful even in different format)
    seager_col = next((c for c in df.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in df.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    
    if seager_col:
        hitting_cats[seager_col] = {'higher_better': True, 'weight': 0.25}
    if ev_col:
        hitting_cats[ev_col] = {'higher_better': True, 'weight': 0.25}
    
    # Create a copy
    df_z = df.copy()
    
    # If no reference dataframe is provided, use the input dataframe
    if reference_df is None:
        reference_df = df.copy()
    
    # Calculate SBN if it's not present but SB and CS are
    if 'SBN' not in df_z.columns and 'SB' in df_z.columns:
        if 'CS' in df_z.columns:
            df_z['SBN'] = df_z['SB'] - df_z['CS']
        else:
            df_z['SBN'] = df_z['SB']  # If CS not available, use SB as approximation
            
    # Fill missing values with category averages before Z-score calculations
    for cat in hitting_cats:
        if cat in df_z.columns and df_z[cat].isna().any():
            category_mean = reference_df[cat].mean() if cat in reference_df.columns else df_z[cat].mean()
            # Add small random variation (±1%) to avoid identical values for missing data
            import random
            df_z[cat] = df_z[cat].apply(
                lambda x: category_mean * (1 + random.uniform(-0.01, 0.01)) if pd.isna(x) else x
            )
    
    # Filter out bottom performers for reference calculations to avoid skewing
    if len(reference_df) > top_n*1.2:  # Only if we have sufficient data
        category_references = {}
        for cat in hitting_cats:
            if cat in reference_df.columns:
                # Sort by category value
                is_higher_better = hitting_cats[cat]['higher_better']
                sorted_ref = reference_df.sort_values(cat, ascending=not is_higher_better)
                # Take top N rows and exclude bottom 20%
                cut_off = int(min(top_n, len(sorted_ref) * 0.8))
                category_references[cat] = sorted_ref.head(cut_off)
    else:
        # Use the whole reference dataset for all categories
        category_references = {cat: reference_df for cat in hitting_cats if cat in reference_df.columns}
    
    # Calculate z-scores for each category
    z_columns = []
    for cat, props in hitting_cats.items():
        if cat in df_z.columns and cat in category_references:
            # Skip if column is all NaN
            if df_z[cat].isna().all() or category_references[cat][cat].isna().all():
                continue
                
            col_z = f"{cat}_z"
            mean = category_references[cat][cat].mean()
            std = category_references[cat][cat].std()
            
            # Avoid division by zero
            if std == 0:
                df_z[col_z] = 0
            else:
                # Calculate z-score based on higher/lower better
                if props['higher_better']:
                    df_z[col_z] = (df_z[cat] - mean) / std
                else:
                    df_z[col_z] = (mean - df_z[cat]) / std
                
                # Cap z-scores at +/- 1.5
                df_z[col_z] = df_z[col_z].clip(-1.5, 1.5)
                    
                # Apply category weight
                df_z[col_z] = df_z[col_z] * props['weight']
            
            z_columns.append(col_z)
    
    # Calculate total z-score
    if z_columns:
        df_z['Total_Z'] = df_z[z_columns].sum(axis=1)
        
        # Reorder columns
        cols = list(df_z.columns)
        name_idx = cols.index('Name') if 'Name' in cols else -1
        if name_idx >= 0:
            cols.remove('Total_Z')
            cols.insert(name_idx + 1, 'Total_Z')
            df_z = df_z[cols]
    
    return df_z

def calculate_zscores_pitchers(df, reference_df=None, top_n=300):
    """
    Calculate Z-scores for pitcher categories and add total Z-score
    Uses a reference dataset or top_n players for calculating mean and std
    """
    if df is None or len(df) == 0:
        return df
    
    # Define categories and weights
    pitching_cats = {
        'K': {'higher_better': True, 'weight': 1.0},
        'ERA': {'higher_better': False, 'weight': 1.0},
        'WHIP': {'higher_better': False, 'weight': 1.0},
        'W': {'higher_better': True, 'weight': 1.0},
        'SV': {'higher_better': True, 'weight': 1.0},
        'QS': {'higher_better': True, 'weight': 1.0},
        'botStf': {'higher_better': True, 'weight': 0.25},
        'Location+': {'higher_better': True, 'weight': 0.25}
    }
    
    # Create a copy
    df_z = df.copy()
    
    # Calculate W+QS if both exist
    if 'W' in df.columns and 'QS' in df.columns:
        df_z['W+QS'] = df['W'] + df['QS']
        pitching_cats['W+QS'] = {'higher_better': True, 'weight': 1.0}
    
    # Calculate K/BB if K and BB exist
    if 'K' in df.columns and 'BB' in df.columns:
        df_z['K/BB'] = df['K'] / df['BB'].replace(0, np.nan)
        df_z['K/BB'] = df_z['K/BB'].fillna(df_z['K/BB'].mean())  # Handle division by zero
        pitching_cats['K/BB'] = {'higher_better': True, 'weight': 1.0}
    elif 'K/BB' in df.columns:
        pitching_cats['K/BB'] = {'higher_better': True, 'weight': 1.0}
        
    # Fill missing values with category averages before Z-score calculations
    for cat in pitching_cats:
        if cat in df_z.columns and df_z[cat].isna().any():
            category_mean = reference_df[cat].mean() if (reference_df is not None 
                                                        and cat in reference_df.columns) else df_z[cat].mean()
            # Add small random variation (±1%) to avoid identical values for missing data
            import random
            df_z[cat] = df_z[cat].apply(
                lambda x: category_mean * (1 + random.uniform(-0.01, 0.01)) if pd.isna(x) else x
            )
    
    # If no reference dataframe is provided, use the input dataframe
    if reference_df is None:
        # For ERA and WHIP, exclude extreme outliers
        reference_df = df.copy()
        if 'ERA' in reference_df.columns:
            reference_df['ERA'] = reference_df['ERA'].clip(lower=1.0, upper=7.0)
        if 'WHIP' in reference_df.columns:
            reference_df['WHIP'] = reference_df['WHIP'].clip(lower=0.8, upper=2.0)
    
    # Filter out bottom performers
    # Keep only top 80% of players for reference calculations to avoid skewing
    if len(reference_df) > top_n*1.2:  # Only if we have sufficient data
        category_references = {}
        for cat in pitching_cats:
            if cat in reference_df.columns:
                # Sort by category value
                is_higher_better = pitching_cats[cat]['higher_better']
                sorted_ref = reference_df.sort_values(cat, ascending=not is_higher_better)
                # Take top N rows and exclude bottom 20%
                cut_off = int(min(top_n, len(sorted_ref) * 0.8))
                category_references[cat] = sorted_ref.head(cut_off)
    else:
        # Use the whole reference dataset for all categories
        category_references = {cat: reference_df for cat in pitching_cats if cat in reference_df.columns}
    
    # Calculate z-scores for each category
    z_columns = []
    for cat, props in pitching_cats.items():
        if cat in df_z.columns and cat in category_references:
            # Skip if column is all NaN
            if df_z[cat].isna().all() or category_references[cat][cat].isna().all():
                continue
                
            col_z = f"{cat}_z"
            mean = category_references[cat][cat].mean()
            std = category_references[cat][cat].std()
            
            # Avoid division by zero
            if std == 0:
                df_z[col_z] = 0
            else:
                # Calculate z-score based on higher/lower better
                if props['higher_better']:
                    df_z[col_z] = (df_z[cat] - mean) / std
                else:
                    df_z[col_z] = (mean - df_z[cat]) / std
                
                # Cap z-scores at +/- 1.5
                df_z[col_z] = df_z[col_z].clip(-1.5, 1.5)
                    
                # Apply category weight
                df_z[col_z] = df_z[col_z] * props['weight']
            
            z_columns.append(col_z)
    
    # Calculate total z-score
    if z_columns:
        df_z['Total_Z'] = df_z[z_columns].sum(axis=1)
        
        # Reorder columns
        cols = list(df_z.columns)
        name_idx = cols.index('Name') if 'Name' in cols else -1
        if name_idx >= 0:
            cols.remove('Total_Z')
            cols.insert(name_idx + 1, 'Total_Z')
            df_z = df_z[cols]
    
    return df_z

def calculate_zscores_pitchers_alt(df, reference_df=None, top_n=300):
    """
    Calculate Z-scores for pitcher categories and add total Z-score
    Uses a reference dataset or top_n players for calculating mean and std
    Adapted for K/9, K/BB, ERA, HR/9, WHIP categories
    """
    if df is None or len(df) == 0:
        return df
    
    # Define categories and weights - MODIFIED FOR NEW LEAGUE
    pitching_cats = {
        'K/9': {'higher_better': True, 'weight': 1.0},
        'K/BB': {'higher_better': True, 'weight': 1.0},
        'ERA': {'higher_better': False, 'weight': 1.0},
        'HR/9': {'higher_better': False, 'weight': 1.0},
        'WHIP': {'higher_better': False, 'weight': 1.0},
        'botStf': {'higher_better': True, 'weight': 0.25},
        'Location+': {'higher_better': True, 'weight': 0.25}
    }
    
    # Create a copy
    df_z = df.copy()
    
    # Calculate needed stats if not present
    if 'K/9' not in df_z.columns and 'K' in df_z.columns and 'IP' in df_z.columns:
        df_z['K/9'] = 9.0 * df_z['K'] / df_z['IP'].replace(0, np.nan)
        df_z['K/9'] = df_z['K/9'].fillna(df_z['K/9'].median())
        
    if 'K/BB' not in df_z.columns and 'K' in df_z.columns and 'BB' in df_z.columns:
        df_z['K/BB'] = df_z['K'] / df_z['BB'].replace(0, np.nan)
        df_z['K/BB'] = df_z['K/BB'].fillna(df_z['K/BB'].median())
    
    if 'HR/9' not in df_z.columns and 'HR' in df_z.columns and 'IP' in df_z.columns:
        df_z['HR/9'] = 9.0 * df_z['HR'] / df_z['IP'].replace(0, np.nan)
        df_z['HR/9'] = df_z['HR/9'].fillna(df_z['HR/9'].median())
    
    # Fill missing values with category averages before Z-score calculations
    for cat in pitching_cats:
        if cat in df_z.columns and df_z[cat].isna().any():
            category_mean = reference_df[cat].mean() if (reference_df is not None 
                                                        and cat in reference_df.columns) else df_z[cat].mean()
            # Add small random variation (±1%) to avoid identical values for missing data
            import random
            df_z[cat] = df_z[cat].apply(
                lambda x: category_mean * (1 + random.uniform(-0.01, 0.01)) if pd.isna(x) else x
            )
    
    # If no reference dataframe is provided, use the input dataframe
    if reference_df is None:
        # For ERA and WHIP, exclude extreme outliers
        reference_df = df.copy()
        if 'ERA' in reference_df.columns:
            reference_df['ERA'] = reference_df['ERA'].clip(lower=1.0, upper=7.0)
        if 'WHIP' in reference_df.columns:
            reference_df['WHIP'] = reference_df['WHIP'].clip(lower=0.8, upper=2.0)
        if 'HR/9' in reference_df.columns:
            reference_df['HR/9'] = reference_df['HR/9'].clip(lower=0, upper=3.0)
    
    # Filter out bottom performers
    if len(reference_df) > top_n*1.2:  # Only if we have sufficient data
        category_references = {}
        for cat in pitching_cats:
            if cat in reference_df.columns:
                # Sort by category value
                is_higher_better = pitching_cats[cat]['higher_better']
                sorted_ref = reference_df.sort_values(cat, ascending=not is_higher_better)
                # Take top N rows and exclude bottom 20%
                cut_off = int(min(top_n, len(sorted_ref) * 0.8))
                category_references[cat] = sorted_ref.head(cut_off)
    else:
        # Use the whole reference dataset for all categories
        category_references = {cat: reference_df for cat in pitching_cats if cat in reference_df.columns}
    
    # Calculate z-scores for each category
    z_columns = []
    for cat, props in pitching_cats.items():
        if cat in df_z.columns and cat in category_references:
            # Skip if column is all NaN
            if df_z[cat].isna().all() or category_references[cat][cat].isna().all():
                continue
                
            col_z = f"{cat}_z"
            mean = category_references[cat][cat].mean()
            std = category_references[cat][cat].std()
            
            # Avoid division by zero
            if std == 0:
                df_z[col_z] = 0
            else:
                # Calculate z-score based on higher/lower better
                if props['higher_better']:
                    df_z[col_z] = (df_z[cat] - mean) / std
                else:
                    df_z[col_z] = (mean - df_z[cat]) / std
                
                # Cap z-scores at +/- 1.5
                df_z[col_z] = df_z[col_z].clip(-1.5, 1.5)
                    
                # Apply category weight
                df_z[col_z] = df_z[col_z] * props['weight']
            
            z_columns.append(col_z)
    
    # Calculate total z-score
    if z_columns:
        df_z['Total_Z'] = df_z[z_columns].sum(axis=1)
        
        # Reorder columns
        cols = list(df_z.columns)
        name_idx = cols.index('Name') if 'Name' in cols else -1
        if name_idx >= 0:
            cols.remove('Total_Z')
            cols.insert(name_idx + 1, 'Total_Z')
            df_z = df_z[cols]
    
    return df_z

def format_dataframe_for_display(df, display_cols, is_pitcher=False):
    """Format dataframe for display, including rounding and column selection"""
    if df is None or len(df) == 0:
        return pd.DataFrame()
    
    df_display = df.copy()
    
    # Calculate K/9 and BB/9 for pitchers if not present
    if is_pitcher:
        if "K/9" not in df.columns and "SO" in df.columns and "IP" in df.columns:
            df_display["K/9"] = 9 * df["SO"] / df["IP"].replace(0, np.nan)
        if "BB/9" not in df.columns and "BB" in df.columns and "IP" in df.columns:
            df_display["BB/9"] = 9 * df["BB"] / df["IP"].replace(0, np.nan)
    
    # Round numeric columns
    for col in df_display.select_dtypes(include=[np.number]).columns:
        if col in df_display.columns:
            if col in ["AVG", "OBP", "SLG", "OPS", "ERA", "WHIP"]:
                df_display[col] = df_display[col].round(3)
            elif col in ["K/9", "BB/9", "K/BB", "HR/9", "Total_Z", "MASH"] or col.endswith("_z") or col.endswith("_mash"):
                df_display[col] = df_display[col].round(2)
            else:
                df_display[col] = df_display[col].round(1)
    
    # Sort by MASH if it exists, otherwise by Total_Z
    if 'MASH' in df_display.columns:
        df_display = df_display.sort_values('MASH', ascending=False)
    elif 'Total_Z' in df_display.columns:
        df_display = df_display.sort_values('Total_Z', ascending=False)
    
    # Build a list of columns to display
    available_cols = []
    
    # Always include Name if it exists
    if 'Name' in df_display.columns:
        available_cols.append('Name')
        
    # Include Team if it exists
    if 'Team' in df_display.columns:
        available_cols.append('Team')
    
    # Include MASH if it exists
    if 'MASH' in df_display.columns:
        available_cols.append('MASH')
        
    # Include Total_Z if it exists
    if 'Total_Z' in df_display.columns:
        available_cols.append('Total_Z')
    
    # Add other display columns if they exist
    for col in display_cols:
        if col in df_display.columns and col not in available_cols:
            available_cols.append(col)
    
    # If we found no valid columns, return first 8 columns
    if not available_cols:
        return df_display.iloc[:, :min(8, df_display.shape[1])]
    
    return df_display[available_cols]

def enhance_daily_projections(daily_hitters, daily_pitchers, profiles=None, botstf=None, location=None):
    """Add supplemental stats to daily projections if possible"""
    
    # Function to match players between dataframes
    def match_players(df1, df2, id_col='IDFANGRAPHS'):
        if id_col in df1.columns and id_col in df2.columns:
            return df1.merge(df2, on=id_col, how='left')
        else:
            # Try fuzzy matching based on Name and Team
            df1_copy = df1.copy()
            name_col = next((c for c in df1.columns if c.lower() == 'name'), 'Name')
            team_col = next((c for c in df1.columns if c.lower() == 'team'), 'Team')
            
            result = {}
            for idx, row in df1.iterrows():
                name = row[name_col] if name_col in row else ""
                team = row[team_col] if team_col in row else ""
                key = f"{name} {team}"
                
                # Find best match in df2
                matches = df2[df2[name_col].str.contains(name, case=False, na=False)]
                if len(matches) > 0:
                    best_match = matches.iloc[0]
                    for col in df2.columns:
                        if col not in df1.columns and col != name_col and col != team_col:
                            if idx not in result:
                                result[idx] = {}
                            result[idx][col] = best_match[col]
            
            # Add matched columns to df1_copy
            for idx, cols in result.items():
                for col, val in cols.items():
                    df1_copy.loc[idx, col] = val
                    
            return df1_copy
    
    # Add SEAGER and 90th Pctile EV to hitters if available
    enhanced_hitters = daily_hitters.copy()
    if profiles is not None:
        seager_col = next((c for c in profiles.columns if c.upper() == "SEAGER"), None)
        ev_col = next((c for c in profiles.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
        
        if seager_col and ev_col:
            profile_subset = profiles[[seager_col, ev_col, 'IDFANGRAPHS']].copy()
            enhanced_hitters = match_players(enhanced_hitters, profile_subset)
            
            # Fill missing supplementary stats with averages
            if seager_col in enhanced_hitters.columns and enhanced_hitters[seager_col].isna().any():
                seager_avg = profiles[seager_col].mean()
                enhanced_hitters[seager_col] = enhanced_hitters[seager_col].fillna(seager_avg)
                
            if ev_col in enhanced_hitters.columns and enhanced_hitters[ev_col].isna().any():
                ev_avg = profiles[ev_col].mean()
                enhanced_hitters[ev_col] = enhanced_hitters[ev_col].fillna(ev_avg)
    
    # Add BotStf and Location+ to pitchers if available
    enhanced_pitchers = daily_pitchers.copy()
    if botstf is not None and 'botStf' in botstf.columns:
        enhanced_pitchers = match_players(enhanced_pitchers, botstf[['IDFANGRAPHS', 'botStf']])
        # Fill missing values with average
        if 'botStf' in enhanced_pitchers.columns and enhanced_pitchers['botStf'].isna().any():
            botStf_avg = botstf['botStf'].mean()
            enhanced_pitchers['botStf'] = enhanced_pitchers['botStf'].fillna(botStf_avg)
    
    if location is not None and 'Location+' in location.columns:
        enhanced_pitchers = match_players(enhanced_pitchers, location[['IDFANGRAPHS', 'Location+']])
        # Fill missing values with average
        if 'Location+' in enhanced_pitchers.columns and enhanced_pitchers['Location+'].isna().any():
            location_avg = location['Location+'].mean()
            enhanced_pitchers['Location+'] = enhanced_pitchers['Location+'].fillna(location_avg)
    
    # Calculate additional stats for alternate league format
    if enhanced_hitters is not None:
        # SBN (Net Stolen Bases)
        if 'SBN' not in enhanced_hitters.columns and 'SB' in enhanced_hitters.columns:
            if 'CS' in enhanced_hitters.columns:
                enhanced_hitters['SBN'] = enhanced_hitters['SB'] - enhanced_hitters['CS']
            else:
                enhanced_hitters['SBN'] = enhanced_hitters['SB']
            
    if enhanced_pitchers is not None:
        # K/9 (Strikeouts per 9 innings)
        if 'K/9' not in enhanced_pitchers.columns and 'K' in enhanced_pitchers.columns and 'IP' in enhanced_pitchers.columns:
            enhanced_pitchers['K/9'] = 9.0 * enhanced_pitchers['K'] / enhanced_pitchers['IP'].replace(0, 0.01)
            
        # K/BB (Strikeout to Walk ratio)
        if 'K/BB' not in enhanced_pitchers.columns and 'K' in enhanced_pitchers.columns and 'BB' in enhanced_pitchers.columns:
            enhanced_pitchers['K/BB'] = enhanced_pitchers['K'] / enhanced_pitchers['BB'].replace(0, 0.01)
            
        # HR/9 (Home Runs per 9 innings)
        if 'HR/9' not in enhanced_pitchers.columns and 'HR' in enhanced_pitchers.columns and 'IP' in enhanced_pitchers.columns:
            enhanced_pitchers['HR/9'] = 9.0 * enhanced_pitchers['HR'] / enhanced_pitchers['IP'].replace(0, 0.01)
    
    # Filter out problematic players
    enhanced_hitters = filter_problematic_players(enhanced_hitters)
    enhanced_pitchers = filter_problematic_players(enhanced_pitchers)
    
    return enhanced_hitters, enhanced_pitchers

def filter_and_export_ros(league_file, standings_file=None, my_team=None):
    """Process ROS projections with league file"""
    # Create temp directory if it doesn't exist
    temp_dir = os.path.join(tempfile.gettempdir(), "ros_filter")
    os.makedirs(temp_dir, exist_ok=True)
    
    top_n = 300  # Top players to use for mean/std calculations
    
    # Load ROS projections
    ros_hitters, ros_pitchers = load_and_aggregate_ros()
    
    # Add MASH calculation if standings file is provided
    category_weights = None
    if standings_file and my_team:
        try:
            category_weights = analyze_standings(standings_file, my_team)
        except Exception as e:
            print(f"Could not calculate category weights: {str(e)}")
    
    try:
        # Load league file
        league_df = pd.read_csv(league_file)
        
        # Debug status values
        status_col = next((c for c in league_df.columns if c.lower() == "status"), None)
        if not status_col:
            return None, None, None, None, None, "No Status column found in league file"
            
        # Get unique statuses
        status_values = sorted(set([str(s).strip() for s in league_df[status_col].unique() if pd.notna(s)]))
        print(f"Status values found: {status_values[:10]}...")
        
        # Filter FA status players 
        valid_fa = "FA" in status_values
        if not valid_fa:
            return None, None, None, None, None, "No 'FA' status found in league file"
            
        # Apply pre-filtering of problematic players
        ros_hitters = filter_problematic_players(ros_hitters)
        ros_pitchers = filter_problematic_players(ros_pitchers)
        
    except Exception as e:
        return None, None, None, None, None, f"Error reading league file: {str(e)}"
    
    # Filter for AFRO players
    afro_hitters, error_msg = filter_players(ros_hitters, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter for FA players
    fa_hitters, error_msg = filter_players(ros_hitters, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for AFRO
    afro_pitchers, error_msg = filter_players(ros_pitchers, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for FA
    fa_pitchers, error_msg = filter_players(ros_pitchers, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Apply further filtering to each dataset
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
    
    # Calculate Z-scores for all dataframes using the full dataset as reference
    if afro_hitters is not None and len(afro_hitters) > 0:
        afro_hitters = calculate_zscores_hitters(afro_hitters, ros_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_hitters = calculate_mash_score(afro_hitters, category_weights, is_pitcher=False)
    
    if fa_hitters is not None and len(fa_hitters) > 0:
        fa_hitters = calculate_zscores_hitters(fa_hitters, ros_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_hitters = calculate_mash_score(fa_hitters, category_weights, is_pitcher=False)
        
        if afro_pitchers is not None and len(afro_pitchers) > 0:
            afro_pitchers = calculate_zscores_pitchers(afro_pitchers, ros_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_pitchers = calculate_mash_score(afro_pitchers, category_weights, is_pitcher=True)
    
    if fa_pitchers is not None and len(fa_pitchers) > 0:
        fa_pitchers = calculate_zscores_pitchers(fa_pitchers, ros_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_pitchers = calculate_mash_score(fa_pitchers, category_weights, is_pitcher=True)
            
    # Apply final filtering to each dataset
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
        # Remove duplicates
        afro_hitters = afro_hitters.drop_duplicates(subset=['Name'])
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
        # Remove duplicates
        fa_hitters = fa_hitters.drop_duplicates(subset=['Name'])
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
        # Remove duplicates
        afro_pitchers = afro_pitchers.drop_duplicates(subset=['Name'])
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
        # Remove duplicates
        fa_pitchers = fa_pitchers.drop_duplicates(subset=['Name'])
    
    # Format dataframes for display
    hits_display_cols = ["R", "HR", "RBI", "SB", "AVG", "OPS", "G", "PA", "AB", "BB"]
    pitch_display_cols = ["GS", "IP", "W", "SV", "K", "ERA", "WHIP", "BB", "K/BB", "botStf", "Location+"]
    
    # Add supplemental stats to display if they exist
    seager_col = next((c for c in ros_hitters.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in ros_hitters.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    if seager_col:
        hits_display_cols.append(seager_col)
    if ev_col:
        hits_display_cols.append(ev_col)
    
    # Safely format dataframes
    afro_hitters_display = format_dataframe_for_display(afro_hitters, hits_display_cols)
    fa_hitters_display = format_dataframe_for_display(fa_hitters, hits_display_cols)
    afro_pitchers_display = format_dataframe_for_display(afro_pitchers, pitch_display_cols, is_pitcher=True)
    fa_pitchers_display = format_dataframe_for_display(fa_pitchers, pitch_display_cols, is_pitcher=True)
    
    # Create download files
    def create_download_file(df, filename):
        if df is None or len(df) == 0:
            empty_df = pd.DataFrame(columns=["No players found"])
            file_path = os.path.join(temp_dir, filename)
            empty_df.to_csv(file_path, index=False)
            return file_path
            
        file_path = os.path.join(temp_dir, filename)
        df.to_csv(file_path, index=False)
        return file_path
    
    afro_hitters_csv = create_download_file(afro_hitters, "ROS_AFRO_hitters.csv")
    fa_hitters_csv = create_download_file(fa_hitters, "ROS_FA_hitters.csv")
    afro_pitchers_csv = create_download_file(afro_pitchers, "ROS_AFRO_pitchers.csv")
    fa_pitchers_csv = create_download_file(fa_pitchers, "ROS_FA_pitchers.csv")
    
    combined_file = os.path.join(temp_dir, "ROS_combined.zip")
    import zipfile
    with zipfile.ZipFile(combined_file, 'w') as zipf:
        if afro_hitters_csv:
            zipf.write(afro_hitters_csv, arcname="ROS_AFRO_hitters.csv")
        if fa_hitters_csv:
            zipf.write(fa_hitters_csv, arcname="ROS_FA_hitters.csv")
        if afro_pitchers_csv:
            zipf.write(afro_pitchers_csv, arcname="ROS_AFRO_pitchers.csv")
        if fa_pitchers_csv:
            zipf.write(fa_pitchers_csv, arcname="ROS_FA_pitchers.csv")
    
    # Count results
    afro_h_count = 0 if afro_hitters is None else len(afro_hitters)
    fa_h_count = 0 if fa_hitters is None else len(fa_hitters)
    afro_p_count = 0 if afro_pitchers is None else len(afro_pitchers)
    fa_p_count = 0 if fa_pitchers is None else len(fa_pitchers)
    
    mash_status = "with MASH scores" if category_weights else "without MASH (no standings file or team name)"
    status_msg = f"Found {afro_h_count} AFRO hitters, {fa_h_count} FA hitters, {afro_p_count} AFRO pitchers, and {fa_p_count} FA pitchers {mash_status}."
    
    return (
        afro_hitters_display, fa_hitters_display, 
        afro_pitchers_display, fa_pitchers_display,
        combined_file, status_msg
    )

def filter_and_export_ros_alt(league_file, standings_file=None, my_team=None):
    """Process ROS projections with league file for alternate league format"""
    # Create temp directory if it doesn't exist
    temp_dir = os.path.join(tempfile.gettempdir(), "ros_filter_alt")
    os.makedirs(temp_dir, exist_ok=True)
    
    top_n = 300  # Top players to use for mean/std calculations
    
    # Load ROS projections
    ros_hitters, ros_pitchers = load_and_aggregate_ros()
    
    # Add MASH calculation if standings file is provided
    category_weights = None
    if standings_file and my_team:
        try:
            category_weights = analyze_standings(standings_file, my_team)
        except Exception as e:
            print(f"Could not calculate category weights: {str(e)}")
    
    try:
        # Load league file
        league_df = pd.read_csv(league_file)
        
        # Debug status values
        status_col = next((c for c in league_df.columns if c.lower() == "status"), None)
        if not status_col:
            return None, None, None, None, None, "No Status column found in league file"
            
        # Get unique statuses
        status_values = sorted(set([str(s).strip() for s in league_df[status_col].unique() if pd.notna(s)]))
        print(f"Status values found: {status_values[:10]}...")
        
        # Filter FA status players 
        valid_fa = "FA" in status_values
        if not valid_fa:
            return None, None, None, None, None, "No 'FA' status found in league file"
            
        # Apply pre-filtering of problematic players
        ros_hitters = filter_problematic_players(ros_hitters)
        ros_pitchers = filter_problematic_players(ros_pitchers)
        
        # Calculate additional stats needed for alt league
        # SBN (Net Stolen Bases)
        if 'SBN' not in ros_hitters.columns and 'SB' in ros_hitters.columns:
            if 'CS' in ros_hitters.columns:
                ros_hitters['SBN'] = ros_hitters['SB'] - ros_hitters['CS']
            else:
                ros_hitters['SBN'] = ros_hitters['SB']
                
        # K/9 (Strikeouts per 9 innings)
        if 'K/9' not in ros_pitchers.columns and 'K' in ros_pitchers.columns and 'IP' in ros_pitchers.columns:
            ros_pitchers['K/9'] = 9.0 * ros_pitchers['K'] / ros_pitchers['IP'].replace(0, 0.01)
            
        # K/BB (Strikeout to Walk ratio)
        if 'K/BB' not in ros_pitchers.columns and 'K' in ros_pitchers.columns and 'BB' in ros_pitchers.columns:
            ros_pitchers['K/BB'] = ros_pitchers['K'] / ros_pitchers['BB'].replace(0, 0.01)
            
        # HR/9 (Home Runs per 9 innings)
        if 'HR/9' not in ros_pitchers.columns and 'HR' in ros_pitchers.columns and 'IP' in ros_pitchers.columns:
            ros_pitchers['HR/9'] = 9.0 * ros_pitchers['HR'] / ros_pitchers['IP'].replace(0, 0.01)
        
    except Exception as e:
        return None, None, None, None, None, f"Error reading league file: {str(e)}"
    
    # Filter for AFRO players
    afro_hitters, error_msg = filter_players(ros_hitters, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter for FA players
    fa_hitters, error_msg = filter_players(ros_hitters, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for AFRO
    afro_pitchers, error_msg = filter_players(ros_pitchers, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for FA
    fa_pitchers, error_msg = filter_players(ros_pitchers, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Apply further filtering to each dataset
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
    
    # Calculate Z-scores for all dataframes using the ALT functions
    if afro_hitters is not None and len(afro_hitters) > 0:
        afro_hitters = calculate_zscores_hitters_alt(afro_hitters, ros_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_hitters = calculate_mash_score_alt(afro_hitters, category_weights, is_pitcher=False)
    
    if fa_hitters is not None and len(fa_hitters) > 0:
        fa_hitters = calculate_zscores_hitters_alt(fa_hitters, ros_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_hitters = calculate_mash_score_alt(fa_hitters, category_weights, is_pitcher=False)
        
    if afro_pitchers is not None and len(afro_pitchers) > 0:
        afro_pitchers = calculate_zscores_pitchers_alt(afro_pitchers, ros_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_pitchers = calculate_mash_score_alt(afro_pitchers, category_weights, is_pitcher=True)
    
    if fa_pitchers is not None and len(fa_pitchers) > 0:
        fa_pitchers = calculate_zscores_pitchers_alt(fa_pitchers, ros_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_pitchers = calculate_mash_score_alt(fa_pitchers, category_weights, is_pitcher=True)
            
    # Apply final filtering to each dataset
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
        # Remove duplicates
        afro_hitters = afro_hitters.drop_duplicates(subset=['Name'])
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
        # Remove duplicates
        fa_hitters = fa_hitters.drop_duplicates(subset=['Name'])
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
        # Remove duplicates
        afro_pitchers = afro_pitchers.drop_duplicates(subset=['Name'])
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
        # Remove duplicates
        fa_pitchers = fa_pitchers.drop_duplicates(subset=['Name'])
    
    # Format dataframes for display - Using ALT league categories
    hits_display_cols = ["HR", "BB", "SBN", "OBP", "SLG", "G", "PA", "AB"]
    pitch_display_cols = ["GS", "IP", "K/9", "K/BB", "ERA", "HR/9", "WHIP", "K", "BB", "botStf", "Location+"]
    
    # Add supplemental stats to display if they exist
    seager_col = next((c for c in ros_hitters.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in ros_hitters.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    if seager_col:
        hits_display_cols.append(seager_col)
    if ev_col:
        hits_display_cols.append(ev_col)
    
    # Safely format dataframes
    afro_hitters_display = format_dataframe_for_display(afro_hitters, hits_display_cols)
    fa_hitters_display = format_dataframe_for_display(fa_hitters, hits_display_cols)
    afro_pitchers_display = format_dataframe_for_display(afro_pitchers, pitch_display_cols, is_pitcher=True)
    fa_pitchers_display = format_dataframe_for_display(fa_pitchers, pitch_display_cols, is_pitcher=True)
    
    # Create download files
    def create_download_file(df, filename):
        if df is None or len(df) == 0:
            empty_df = pd.DataFrame(columns=["No players found"])
            file_path = os.path.join(temp_dir, filename)
            empty_df.to_csv(file_path, index=False)
            return file_path
            
        file_path = os.path.join(temp_dir, filename)
        df.to_csv(file_path, index=False)
        return file_path
    
    afro_hitters_csv = create_download_file(afro_hitters, "ROS_AFRO_hitters_alt.csv")
    fa_hitters_csv = create_download_file(fa_hitters, "ROS_FA_hitters_alt.csv")
    afro_pitchers_csv = create_download_file(afro_pitchers, "ROS_AFRO_pitchers_alt.csv")
    fa_pitchers_csv = create_download_file(fa_pitchers, "ROS_FA_pitchers_alt.csv")
    
    combined_file = os.path.join(temp_dir, "ROS_combined_alt.zip")
    import zipfile
    with zipfile.ZipFile(combined_file, 'w') as zipf:
        if afro_hitters_csv:
            zipf.write(afro_hitters_csv, arcname="ROS_AFRO_hitters_alt.csv")
        if fa_hitters_csv:
            zipf.write(fa_hitters_csv, arcname="ROS_FA_hitters_alt.csv")
        if afro_pitchers_csv:
            zipf.write(afro_pitchers_csv, arcname="ROS_AFRO_pitchers_alt.csv")
        if fa_pitchers_csv:
            zipf.write(fa_pitchers_csv, arcname="ROS_FA_pitchers_alt.csv")
    
    # Count results
    afro_h_count = 0 if afro_hitters is None else len(afro_hitters)
    fa_h_count = 0 if fa_hitters is None else len(fa_hitters)
    afro_p_count = 0 if afro_pitchers is None else len(afro_pitchers)
    fa_p_count = 0 if fa_pitchers is None else len(fa_pitchers)
    
    mash_status = "with MASH scores" if category_weights else "without MASH (no standings file or team name)"
    status_msg = f"Found {afro_h_count} AFRO hitters, {fa_h_count} FA hitters, {afro_p_count} AFRO pitchers, and {fa_p_count} FA pitchers {mash_status} for ALT league."
    
    return (
        afro_hitters_display, fa_hitters_display, 
        afro_pitchers_display, fa_pitchers_display,
        combined_file, status_msg
    )

def filter_and_export_daily(league_file, daily_hitters_file, daily_pitchers_file, standings_file=None, my_team=None):
    """Process daily projections with league file"""
    # Create temp directory if it doesn't exist
    temp_dir = os.path.join(tempfile.gettempdir(), "daily_filter")
    os.makedirs(temp_dir, exist_ok=True)

    top_n = 100  # Top players to use for mean/std calculations for daily (smaller pool)

    # Add MASH calculation if standings file is provided
    category_weights = None
    if standings_file and my_team:
        try:
            category_weights = analyze_standings(standings_file, my_team)
        except Exception as e:
            print(f"Could not calculate category weights: {str(e)}")
    
    try:
        league_df = pd.read_csv(league_file)
        daily_hitters = pd.read_csv(daily_hitters_file)
        daily_pitchers = pd.read_csv(daily_pitchers_file)
        
        # Print column names for debugging
        print(f"Daily hitters columns: {daily_hitters.columns.tolist()[:10]}...")
        print(f"Daily pitchers columns: {daily_pitchers.columns.tolist()[:10]}...")
        print(f"League file columns: {league_df.columns.tolist()[:10]}...")
        
        # Find and standardize name columns - helps with matching
        for df, name in [(daily_hitters, "daily_hitters"), (daily_pitchers, "daily_pitchers"), (league_df, "league")]:
            name_col = None
            for col in df.columns:
                if col.lower() == 'name' or 'player' in col.lower():
                    name_col = col
                    break
                    
            if name_col and name_col != 'Name':
                print(f"Renaming {name_col} to Name in {name}")
                df.rename(columns={name_col: 'Name'}, inplace=True)
        
        # Load supplementary data
        try:
            profiles = pd.read_csv('Combined_Sorted_Profiles.csv')
            botstf = pd.read_csv('BotStf.csv')
            location = pd.read_csv('Location+.csv')
            
            # Add supplementary stats to daily projections
            daily_hitters, daily_pitchers = enhance_daily_projections(daily_hitters, daily_pitchers, profiles, botstf, location)
        except Exception as e:
            print(f"Could not load supplemental stats: {str(e)}")
            # Continue without supplemental stats if files not found
            pass
            
        # Pre-filter problematic players
        daily_hitters = filter_problematic_players(daily_hitters)
        daily_pitchers = filter_problematic_players(daily_pitchers)
        
    except Exception as e:
        return None, None, None, None, None, f"Error reading files: {str(e)}"
    
    # Filter for AFRO players
    afro_hitters, error_msg = filter_players(daily_hitters, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter for FA players
    fa_hitters, error_msg = filter_players(daily_hitters, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for AFRO
    afro_pitchers, error_msg = filter_players(daily_pitchers, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for FA
    fa_pitchers, error_msg = filter_players(daily_pitchers, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Apply post-filtering 
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
    
    # Calculate Z-scores for all dataframes - using the full daily dataset as reference
    if afro_hitters is not None and len(afro_hitters) > 0:
        afro_hitters = calculate_zscores_hitters(afro_hitters, daily_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_hitters = calculate_mash_score(afro_hitters, category_weights, is_pitcher=False)
        
    if fa_hitters is not None and len(fa_hitters) > 0:
        fa_hitters = calculate_zscores_hitters(fa_hitters, daily_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_hitters = calculate_mash_score(fa_hitters, category_weights, is_pitcher=False)
        
    if afro_pitchers is not None and len(afro_pitchers) > 0:
        afro_pitchers = calculate_zscores_pitchers(afro_pitchers, daily_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_pitchers = calculate_mash_score(afro_pitchers, category_weights, is_pitcher=True)
        
    if fa_pitchers is not None and len(fa_pitchers) > 0:
        fa_pitchers = calculate_zscores_pitchers(fa_pitchers, daily_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_pitchers = calculate_mash_score(fa_pitchers, category_weights, is_pitcher=True)
            
    # Final filtering and deduplication
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
        afro_hitters = afro_hitters.drop_duplicates(subset=['Name'])
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
        fa_hitters = fa_hitters.drop_duplicates(subset=['Name'])
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
        afro_pitchers = afro_pitchers.drop_duplicates(subset=['Name'])
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
        fa_pitchers = fa_pitchers.drop_duplicates(subset=['Name'])
    
    # Format dataframes for display
    hits_display_cols = ["R", "HR", "RBI", "SB", "AVG", "OPS", "G", "PA", "AB", "BB"]
    pitch_display_cols = ["GS", "IP", "W", "SV", "K", "ERA", "WHIP", "BB", "K/BB", "botStf", "Location+"]
    
    # Add supplemental stats to display if they exist
    seager_col = next((c for c in daily_hitters.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in daily_hitters.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    if seager_col:
        hits_display_cols.append(seager_col)
    if ev_col:
        hits_display_cols.append(ev_col)
    
    # Safely format dataframes
    afro_hitters_display = format_dataframe_for_display(afro_hitters, hits_display_cols)
    fa_hitters_display = format_dataframe_for_display(fa_hitters, hits_display_cols)
    afro_pitchers_display = format_dataframe_for_display(afro_pitchers, pitch_display_cols, is_pitcher=True)
    fa_pitchers_display = format_dataframe_for_display(fa_pitchers, pitch_display_cols, is_pitcher=True)
    
    # Create download files
    def create_download_file(df, filename):
        if df is None or len(df) == 0:
            empty_df = pd.DataFrame(columns=["No players found"])
            file_path = os.path.join(temp_dir, filename)
            empty_df.to_csv(file_path, index=False)
            return file_path
            
        file_path = os.path.join(temp_dir, filename)
        df.to_csv(file_path, index=False)
        return file_path
    
    afro_hitters_csv = create_download_file(afro_hitters, "Daily_AFRO_hitters.csv")
    fa_hitters_csv = create_download_file(fa_hitters, "Daily_FA_hitters.csv")
    afro_pitchers_csv = create_download_file(afro_pitchers, "Daily_AFRO_pitchers.csv")
    fa_pitchers_csv = create_download_file(fa_pitchers, "Daily_FA_pitchers.csv")
    
    combined_file = os.path.join(temp_dir, "Daily_combined.zip")
    import zipfile
    with zipfile.ZipFile(combined_file, 'w') as zipf:
        if afro_hitters_csv:
            zipf.write(afro_hitters_csv, arcname="Daily_AFRO_hitters.csv")
        if fa_hitters_csv:
            zipf.write(fa_hitters_csv, arcname="Daily_FA_hitters.csv")
        if afro_pitchers_csv:
            zipf.write(afro_pitchers_csv, arcname="Daily_AFRO_pitchers.csv")
        if fa_pitchers_csv:
            zipf.write(fa_pitchers_csv, arcname="Daily_FA_pitchers.csv")
    
    # Count results
    afro_h_count = 0 if afro_hitters is None else len(afro_hitters)
    fa_h_count = 0 if fa_hitters is None else len(fa_hitters)
    afro_p_count = 0 if afro_pitchers is None else len(afro_pitchers)
    fa_p_count = 0 if fa_pitchers is None else len(fa_pitchers)
    
    mash_status = "with MASH scores" if category_weights else "without MASH (no standings file or team name)"
    status_msg = f"Found {afro_h_count} AFRO hitters, {fa_h_count} FA hitters, {afro_p_count} AFRO pitchers, and {fa_p_count} FA pitchers {mash_status}."
    
    return (
        afro_hitters_display, fa_hitters_display, 
        afro_pitchers_display, fa_pitchers_display,
        combined_file, status_msg
    )

def filter_and_export_daily_alt(league_file, daily_hitters_file, daily_pitchers_file, standings_file=None, my_team=None):
    """Process daily projections with league file for alternate league format"""
    # Create temp directory if it doesn't exist
    temp_dir = os.path.join(tempfile.gettempdir(), "daily_filter_alt")
    os.makedirs(temp_dir, exist_ok=True)

    top_n = 100  # Top players to use for mean/std calculations for daily (smaller pool)

    # Add MASH calculation if standings file is provided
    category_weights = None
    if standings_file and my_team:
        try:
            category_weights = analyze_standings(standings_file, my_team)
        except Exception as e:
            print(f"Could not calculate category weights: {str(e)}")
    
    try:
        league_df = pd.read_csv(league_file)
        daily_hitters = pd.read_csv(daily_hitters_file)
        daily_pitchers = pd.read_csv(daily_pitchers_file)
        
        # Print column names for debugging
        print(f"Daily hitters columns: {daily_hitters.columns.tolist()[:10]}...")
        print(f"Daily pitchers columns: {daily_pitchers.columns.tolist()[:10]}...")
        print(f"League file columns: {league_df.columns.tolist()[:10]}...")
        
        # Find and standardize name columns - helps with matching
        for df, name in [(daily_hitters, "daily_hitters"), (daily_pitchers, "daily_pitchers"), (league_df, "league")]:
            name_col = None
            for col in df.columns:
                if col.lower() == 'name' or 'player' in col.lower():
                    name_col = col
                    break
                    
            if name_col and name_col != 'Name':
                print(f"Renaming {name_col} to Name in {name}")
                df.rename(columns={name_col: 'Name'}, inplace=True)
        
        # Load supplementary data
        try:
            profiles = pd.read_csv('Combined_Sorted_Profiles.csv')
            botstf = pd.read_csv('BotStf.csv')
            location = pd.read_csv('Location+.csv')
            
            # Add supplementary stats to daily projections
            daily_hitters, daily_pitchers = enhance_daily_projections(daily_hitters, daily_pitchers, profiles, botstf, location)
        except Exception as e:
            print(f"Could not load supplemental stats: {str(e)}")
            # Continue without supplemental stats if files not found
            pass
            
        # Add/calculate additional stats for alternate league format
        # SBN (Net Stolen Bases)
        if 'SBN' not in daily_hitters.columns and 'SB' in daily_hitters.columns:
            if 'CS' in daily_hitters.columns:
                daily_hitters['SBN'] = daily_hitters['SB'] - daily_hitters['CS']
            else:
                daily_hitters['SBN'] = daily_hitters['SB']
                
        # K/9 (Strikeouts per 9 innings)
        if 'K/9' not in daily_pitchers.columns and 'K' in daily_pitchers.columns and 'IP' in daily_pitchers.columns:
            daily_pitchers['K/9'] = 9.0 * daily_pitchers['K'] / daily_pitchers['IP'].replace(0, 0.01)
            
        # K/BB (Strikeout to Walk ratio)
        if 'K/BB' not in daily_pitchers.columns and 'K' in daily_pitchers.columns and 'BB' in daily_pitchers.columns:
            daily_pitchers['K/BB'] = daily_pitchers['K'] / daily_pitchers['BB'].replace(0, 0.01)
            
        # HR/9 (Home Runs per 9 innings)
        if 'HR/9' not in daily_pitchers.columns and 'HR' in daily_pitchers.columns and 'IP' in daily_pitchers.columns:
            daily_pitchers['HR/9'] = 9.0 * daily_pitchers['HR'] / daily_pitchers['IP'].replace(0, 0.01)
            
        # Pre-filter problematic players
        daily_hitters = filter_problematic_players(daily_hitters)
        daily_pitchers = filter_problematic_players(daily_pitchers)
        
    except Exception as e:
        return None, None, None, None, None, f"Error reading files: {str(e)}"
    
    # Filter for AFRO players
    afro_hitters, error_msg = filter_players(daily_hitters, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter for FA players
    fa_hitters, error_msg = filter_players(daily_hitters, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for AFRO
    afro_pitchers, error_msg = filter_players(daily_pitchers, league_df, ["AFRO"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Filter pitchers for FA
    fa_pitchers, error_msg = filter_players(daily_pitchers, league_df, ["FA"])
    if error_msg and "No players found" not in error_msg:
        return None, None, None, None, None, error_msg
    
    # Apply post-filtering 
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
    
    # Calculate Z-scores for all dataframes - using the ALT functions
    if afro_hitters is not None and len(afro_hitters) > 0:
        afro_hitters = calculate_zscores_hitters_alt(afro_hitters, daily_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_hitters = calculate_mash_score_alt(afro_hitters, category_weights, is_pitcher=False)
        
    if fa_hitters is not None and len(fa_hitters) > 0:
        fa_hitters = calculate_zscores_hitters_alt(fa_hitters, daily_hitters, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_hitters = calculate_mash_score_alt(fa_hitters, category_weights, is_pitcher=False)
        
    if afro_pitchers is not None and len(afro_pitchers) > 0:
        afro_pitchers = calculate_zscores_pitchers_alt(afro_pitchers, daily_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            afro_pitchers = calculate_mash_score_alt(afro_pitchers, category_weights, is_pitcher=True)
        
    if fa_pitchers is not None and len(fa_pitchers) > 0:
        fa_pitchers = calculate_zscores_pitchers_alt(fa_pitchers, daily_pitchers, top_n=top_n)
        # Add MASH if we have category weights
        if category_weights:
            fa_pitchers = calculate_mash_score_alt(fa_pitchers, category_weights, is_pitcher=True)
            
    # Final filtering and deduplication
    if afro_hitters is not None:
        afro_hitters = filter_problematic_players(afro_hitters)
        afro_hitters = afro_hitters.drop_duplicates(subset=['Name'])
    if fa_hitters is not None:
        fa_hitters = filter_problematic_players(fa_hitters)
        fa_hitters = fa_hitters.drop_duplicates(subset=['Name'])
    if afro_pitchers is not None:
        afro_pitchers = filter_problematic_players(afro_pitchers)
        afro_pitchers = afro_pitchers.drop_duplicates(subset=['Name'])
    if fa_pitchers is not None:
        fa_pitchers = filter_problematic_players(fa_pitchers)
        fa_pitchers = fa_pitchers.drop_duplicates(subset=['Name'])
    
    # Format dataframes for display - ALT league categories
    hits_display_cols = ["HR", "BB", "SBN", "OBP", "SLG", "G", "PA", "AB"]
    pitch_display_cols = ["GS", "IP", "K/9", "K/BB", "ERA", "HR/9", "WHIP", "K", "BB", "botStf", "Location+"]
    
    # Add supplemental stats to display if they exist
    seager_col = next((c for c in daily_hitters.columns if c.upper() == "SEAGER"), None)
    ev_col = next((c for c in daily_hitters.columns if "90TH" in c.upper() and "EV" in c.upper()), None)
    if seager_col:
        hits_display_cols.append(seager_col)
    if ev_col:
        hits_display_cols.append(ev_col)
    
    # Safely format dataframes
    afro_hitters_display = format_dataframe_for_display(afro_hitters, hits_display_cols)
    fa_hitters_display = format_dataframe_for_display(fa_hitters, hits_display_cols)
    afro_pitchers_display = format_dataframe_for_display(afro_pitchers, pitch_display_cols, is_pitcher=True)
    fa_pitchers_display = format_dataframe_for_display(fa_pitchers, pitch_display_cols, is_pitcher=True)
    
    # Create download files
    def create_download_file(df, filename):
        if df is None or len(df) == 0:
            empty_df = pd.DataFrame(columns=["No players found"])
            file_path = os.path.join(temp_dir, filename)
            empty_df.to_csv(file_path, index=False)
            return file_path
            
        file_path = os.path.join(temp_dir, filename)
        df.to_csv(file_path, index=False)
        return file_path
    
    afro_hitters_csv = create_download_file(afro_hitters, "Daily_AFRO_hitters_alt.csv")
    fa_hitters_csv = create_download_file(fa_hitters, "Daily_FA_hitters_alt.csv")
    afro_pitchers_csv = create_download_file(afro_pitchers, "Daily_AFRO_pitchers_alt.csv")
    fa_pitchers_csv = create_download_file(fa_pitchers, "Daily_FA_pitchers_alt.csv")
    
    combined_file = os.path.join(temp_dir, "Daily_combined_alt.zip")
    import zipfile
    with zipfile.ZipFile(combined_file, 'w') as zipf:
        if afro_hitters_csv:
            zipf.write(afro_hitters_csv, arcname="Daily_AFRO_hitters_alt.csv")
        if fa_hitters_csv:
            zipf.write(fa_hitters_csv, arcname="Daily_FA_hitters_alt.csv")
        if afro_pitchers_csv:
            zipf.write(afro_pitchers_csv, arcname="Daily_AFRO_pitchers_alt.csv")
        if fa_pitchers_csv:
            zipf.write(fa_pitchers_csv, arcname="Daily_FA_pitchers_alt.csv")
    
    # Count results
    afro_h_count = 0 if afro_hitters is None else len(afro_hitters)
    fa_h_count = 0 if fa_hitters is None else len(fa_hitters)
    afro_p_count = 0 if afro_pitchers is None else len(afro_pitchers)
    fa_p_count = 0 if fa_pitchers is None else len(fa_pitchers)
    
    mash_status = "with MASH scores" if category_weights else "without MASH (no standings file or team name)"
    status_msg = f"Found {afro_h_count} AFRO hitters, {fa_h_count} FA hitters, {afro_p_count} AFRO pitchers, and {fa_p_count} FA pitchers {mash_status} for ALT league."
    
    return (
        afro_hitters_display, fa_hitters_display, 
        afro_pitchers_display, fa_pitchers_display,
        combined_file, status_msg
    )

def optimize_daily_lineup(daily_hitters_file=None, league_file=None, standings_file=None, my_team=None):
    """Create an optimized daily lineup based on MASH scores"""
    if not daily_hitters_file or not league_file:
        return None, None, "Please upload required files"
        
    # Create temp directory
    temp_dir = os.path.join(tempfile.gettempdir(), "lineup_optimizer")
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        # Load and process files
        daily_hitters = pd.read_csv(daily_hitters_file)
        league_df = pd.read_csv(league_file)
        
        # Debug column names - print the first few columns of each file to help diagnose issues
        print(f"Daily hitters columns: {daily_hitters.columns.tolist()[:10]}...")
        print(f"League file columns: {league_df.columns.tolist()[:10]}...")
        
        # Find the name column in daily hitters
        name_col_daily = None
        for col in daily_hitters.columns:
            if col.lower() == 'name' or 'player' in col.lower():
                name_col_daily = col
                break
                
        if not name_col_daily:
            return None, None, f"Could not find player name column in daily projections. Available columns: {daily_hitters.columns.tolist()[:10]}..."
            
        # Find the name column in league file
        name_col_league = None
        for col in league_df.columns:
            if col.lower() == 'name' or 'player' in col.lower():
                name_col_league = col
                break
                
        if not name_col_league:
            return None, None, f"Could not find player name column in league file. Available columns: {league_df.columns.tolist()[:10]}..."
        
        # Rename columns for consistency
        daily_hitters = daily_hitters.rename(columns={name_col_daily: 'Name'})
        league_df = league_df.rename(columns={name_col_league: 'Name'})
        
        # Load supplementary data
        try:
            profiles = pd.read_csv('Combined_Sorted_Profiles.csv')
            daily_hitters, _ = enhance_daily_projections(daily_hitters, pd.DataFrame(), profiles)
        except Exception as e:
            print(f"Could not load supplemental stats: {str(e)}")
        
        # Pre-filter problematic players
        daily_hitters = filter_problematic_players(daily_hitters)
        
        # Look for team name in Status column
        status_col = next((c for c in league_df.columns if c.lower() == "status"), None)
        if not status_col:
            return None, None, "No status column found in league file"
            
        if not my_team:
            return None, None, "Team name is required for lineup optimization"
            
        # Get players on your team (where Status equals your team name)
        my_players = league_df[league_df[status_col] == my_team]
        
        if len(my_players) == 0:
            # Check if there are any close matches to your team name
            all_statuses = league_df[status_col].dropna().unique()
            best_matches = [(status, process.extractOne(my_team, [status])[1]) 
                           for status in all_statuses if isinstance(status, str)]
            best_match = max(best_matches, key=lambda x: x[1])[0] if best_matches else None
            
            if best_match and best_match != my_team:
                return None, None, f"Team '{my_team}' not found. Did you mean '{best_match}'?"
            return None, None, f"No players found for team '{my_team}' in the league file."
            
        print(f"Found {len(my_players)} players on team {my_team}")
            
        # Get positions for these players
        pos_col = next((c for c in league_df.columns if "pos" in c.lower()), None)
        if not pos_col:
            return None, None, "No position column found in league file"
            
        # Create a dictionary mapping player names to their positions
        positions = {}
        for _, row in my_players.iterrows():
            if 'Name' in row and pos_col in row:
                player_name = row['Name'].lower().strip()
                positions[player_name] = row[pos_col]
        
        # Add position to daily projections
        my_daily_projs = daily_hitters.copy()
        my_daily_projs['Positions'] = my_daily_projs['Name'].str.lower().str.strip().map(positions)
        
        # Filter to only players that have positions (i.e., are on my team)
        my_daily_projs = my_daily_projs[~my_daily_projs['Positions'].isna()]
        
        # If no players found, try more aggressive matching
        if len(my_daily_projs) == 0:
            # Try matching by last name
            lastname_map = {}
            for daily_name in daily_hitters['Name']:
                if not isinstance(daily_name, str):
                    continue
                daily_last = daily_name.split()[-1].lower()
                for _, row in my_players.iterrows():
                    league_name = row['Name'] if isinstance(row['Name'], str) else ""
                    league_last = league_name.split()[-1].lower() if league_name else ""
                    if daily_last and league_last and daily_last == league_last:
                        lastname_map[daily_name] = row[pos_col]
            
            if lastname_map:
                my_daily_projs = daily_hitters.copy()
                my_daily_projs['Positions'] = my_daily_projs['Name'].map(lastname_map)
                my_daily_projs = my_daily_projs[~my_daily_projs['Positions'].isna()]
            else:
                return None, None, f"No matching players found between daily projections and your team '{my_team}'."
                
        # See how many players we matched
        print(f"Matched {len(my_daily_projs)} players between daily projections and team roster")
        
        # Remove duplicates
        my_daily_projs = my_daily_projs.drop_duplicates(subset=['Name'])
        
        # If no players found after filtering, return error
        if len(my_daily_projs) == 0:
            return None, None, "No players found in today's projections for your team after filtering"
            
        # Key stat columns to keep
        stat_cols = []
        for col in ['R', 'HR', 'RBI', 'SB', 'AVG', 'OPS', 'AB', 'PA', 'H']:
            if col in my_daily_projs.columns:
                stat_cols.append(col)
                
        # Calculate Z-scores and MASH
        top_n = 100  # Daily top players for reference
        my_daily_projs = calculate_zscores_hitters(my_daily_projs, daily_hitters, top_n=top_n)
        
        # Find z-score columns
        z_cols = [col for col in my_daily_projs.columns if col.endswith('_z')]
        
        # Add MASH if we have category weights
        category_weights = None
        if standings_file and my_team:
            try:
                category_weights = analyze_standings(standings_file, my_team)
                my_daily_projs = calculate_mash_score(my_daily_projs, category_weights, is_pitcher=False)
            except Exception as e:
                print(f"Error calculating MASH: {str(e)}")
        
        # If we don't have MASH scores, use Total_Z
        score_col = 'MASH' if 'MASH' in my_daily_projs.columns else 'Total_Z'
        if score_col not in my_daily_projs.columns:
            return None, None, "No optimization score column found"
        
        # Sort by optimization score
        my_daily_projs = my_daily_projs.sort_values(score_col, ascending=False)
        
        # Define positions and their priorities
        position_order = ['C', 'C', '1B', '2B', '3B', 'SS', 'CI', 'MI', 'OF', 'OF', 'OF', 'OF', 'OF', 'UTIL']
        position_map = {
            'C': ['C'],
            '1B': ['1B'],
            '2B': ['2B'],
            '3B': ['3B'],
            'SS': ['SS'],
            'CI': ['1B', '3B'],
            'MI': ['2B', 'SS'],
            'OF': ['OF', 'LF', 'CF', 'RF'],
            'UTIL': ['C', '1B', '2B', '3B', 'SS', 'OF', 'DH', 'UTIL', 'UT', 'LF', 'CF', 'RF']
        }
        
        # Function to gather player stats for the final dataframe
        def create_player_entry(player, position):
            entry = {
                'Position': position,
                'Name': player['Name'] if 'Name' in player else 'EMPTY',
                'Positions': player['Positions'] if 'Positions' in player else '',
                score_col: player[score_col] if score_col in player else 0,
                'Team': player['Team'] if 'Team' in player else ''
            }
            
            # Add the projected stats
        for col in stat_cols:
                if col in player:
                    entry[col] = player[col]
                    
            # Add the z-scores
        for col in z_cols:
                if col in player:
                    entry[col] = player[col]
                    
        return entry
        
        # Optimize lineup
        lineup = []
        bench = []
        used_players = set()
        
        # First pass - fill positions in order
        for pos in position_order:
            eligible_players = []
            for _, player in my_daily_projs.iterrows():
                if player['Name'] in used_players:
                    continue
                
                if 'Positions' in player and player['Positions']:
                    player_positions = str(player['Positions']).upper().split('/')
                    # Check if player can play this position
                    is_eligible = False
                    for valid_pos in position_map[pos]:
                        if any(valid_pos in p for p in player_positions):
                            is_eligible = True
                            break
                    
                    if is_eligible:
                        eligible_players.append(player)
            
            # If we found eligible players, use the one with highest MASH
            if eligible_players:
                best_player = max(eligible_players, key=lambda x: x[score_col])
                lineup.append(create_player_entry(best_player, pos))
                used_players.add(best_player['Name'])
            else:
                # Add EMPTY entry when no player is available
                lineup.append({'Position': pos, 'Name': 'EMPTY', 'Positions': '', score_col: 0, 'Team': ''})
        
        # Second pass - put remaining players on bench
        for _, player in my_daily_projs.iterrows():
            if player['Name'] not in used_players:
                bench.append(create_player_entry(player, 'Bench'))
        
        # Sort bench by score (highest to lowest)
        bench = sorted(bench, key=lambda x: x[score_col], reverse=True)
        
        # Create the output DataFrame
        lineup_df = pd.DataFrame(lineup)
        bench_df = pd.DataFrame(bench)
        
        # Combine lineup and bench
        full_roster = pd.concat([lineup_df, bench_df]).reset_index(drop=True)
        
        # Round numeric columns in the display dataframe
        for col in full_roster.select_dtypes(include=[np.number]).columns:
            if col in ['AVG', 'OBP', 'SLG', 'OPS']:
                full_roster[col] = full_roster[col].round(3)
            elif col.endswith('_z') or col == 'MASH' or col == 'Total_Z':
                full_roster[col] = full_roster[col].round(2)
            else:
                full_roster[col] = full_roster[col].round(1)
        
        # Calculate total MASH for the lineup
        lineup_total = (lineup_df[score_col].sum() if score_col in lineup_df.columns 
                        and len(lineup_df) > 0 else 0)
        
        # Create download file
        file_path = os.path.join(temp_dir, "optimized_lineup.csv")
        full_roster.to_csv(file_path, index=False)
        
        # Add a message at the bottom with the total
        status_msg = f"Optimized lineup total {score_col}: {lineup_total:.2f}"
        
        return full_roster, file_path, status_msg
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"Error details: {error_details}")
        return None, None, f"Error optimizing lineup: {str(e)}"

def optimize_daily_lineup_alt(daily_hitters_file=None, league_file=None, standings_file=None, my_team=None):
    """Create an optimized daily lineup based on MASH scores for alternate league format"""
    if not daily_hitters_file or not league_file:
        return None, None, "Please upload required files"
        
    # Create temp directory
    temp_dir = os.path.join(tempfile.gettempdir(), "lineup_optimizer_alt")
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        # Load and process files
        daily_hitters = pd.read_csv(daily_hitters_file)
        league_df = pd.read_csv(league_file)
        
        # Debug column names - print the first few columns of each file to help diagnose issues
        print(f"Daily hitters columns: {daily_hitters.columns.tolist()[:10]}...")
        print(f"League file columns: {league_df.columns.tolist()[:10]}...")
        
        # Find the name column in daily hitters
        name_col_daily = None
        for col in daily_hitters.columns:
            if col.lower() == 'name' or 'player' in col.lower():
                name_col_daily = col
                break
                
        if not name_col_daily:
            return None, None, f"Could not find player name column in daily projections. Available columns: {daily_hitters.columns.tolist()[:10]}..."
            
        # Find the name column in league file
        name_col_league = None
        for col in league_df.columns:
            if col.lower() == 'name' or 'player' in col.lower():
                name_col_league = col
                break
                
        if not name_col_league:
            return None, None, f"Could not find player name column in league file. Available columns: {league_df.columns.tolist()[:10]}..."
        
        # Rename columns for consistency
        daily_hitters = daily_hitters.rename(columns={name_col_daily: 'Name'})
        league_df = league_df.rename(columns={name_col_league: 'Name'})
        
        # Load supplementary data
        try:
            profiles = pd.read_csv('Combined_Sorted_Profiles.csv')
            daily_hitters, _ = enhance_daily_projections(daily_hitters, pd.DataFrame(), profiles)
        except Exception as e:
            print(f"Could not load supplemental stats: {str(e)}")
        
        # Pre-filter problematic players
        daily_hitters = filter_problematic_players(daily_hitters)
        
        # Calculate additional stats for alternate league format
        # SBN (Net Stolen Bases)
        if 'SBN' not in daily_hitters.columns and 'SB' in daily_hitters.columns:
            if 'CS' in daily_hitters.columns:
                daily_hitters['SBN'] = daily_hitters['SB'] - daily_hitters['CS']
            else:
                daily_hitters['SBN'] = daily_hitters['SB']
        
        # Look for team name in Status column
        status_col = next((c for c in league_df.columns if c.lower() == "status"), None)
        if not status_col:
            return None, None, "No status column found in league file"
            
        if not my_team:
            return None, None, "Team name is required for lineup optimization"
            
        # Get players on your team (where Status equals your team name)
        my_players = league_df[league_df[status_col] == my_team]
        
        if len(my_players) == 0:
            # Check if there are any close matches to your team name
            all_statuses = league_df[status_col].dropna().unique()
            best_matches = [(status, process.extractOne(my_team, [status])[1]) 
                           for status in all_statuses if isinstance(status, str)]
            best_match = max(best_matches, key=lambda x: x[1])[0] if best_matches else None
            
            if best_match and best_match != my_team:
                return None, None, f"Team '{my_team}' not found. Did you mean '{best_match}'?"
            return None, None, f"No players found for team '{my_team}' in the league file."
            
        print(f"Found {len(my_players)} players on team {my_team}")
            
        # Get positions for these players
        pos_col = next((c for c in league_df.columns if "pos" in c.lower()), None)
        if not pos_col:
            return None, None, "No position column found in league file"
            
        # Create a dictionary mapping player names to their positions
        positions = {}
        for _, row in my_players.iterrows():
            if 'Name' in row and pos_col in row:
                player_name = row['Name'].lower().strip()
                positions[player_name] = row[pos_col]
        
        # Add position to daily projections
        my_daily_projs = daily_hitters.copy()
        my_daily_projs['Positions'] = my_daily_projs['Name'].str.lower().str.strip().map(positions)
        
        # Filter to only players that have positions (i.e., are on my team)
        my_daily_projs = my_daily_projs[~my_daily_projs['Positions'].isna()]
        
        # If no players found, try more aggressive matching
        if len(my_daily_projs) == 0:
            # Try matching by last name
            lastname_map = {}
            for daily_name in daily_hitters['Name']:
                if not isinstance(daily_name, str):
                    continue
                daily_last = daily_name.split()[-1].lower()
                for _, row in my_players.iterrows():
                    league_name = row['Name'] if isinstance(row['Name'], str) else ""
                    league_last = league_name.split()[-1].lower() if league_name else ""
                    if daily_last and league_last and daily_last == league_last:
                        lastname_map[daily_name] = row[pos_col]
    
            if lastname_map:
                my_daily_projs = daily_hitters.copy()
                my_daily_projs['Positions'] = my_daily_projs['Name'].map(lastname_map)
                my_daily_projs = my_daily_projs[~my_daily_projs['Positions'].isna()]
            else:
                return None, None, f"No matching players found between daily projections and your team '{my_team}'."


        # See how many players we matched
        print(f"Matched {len(my_daily_projs)} players between daily projections and team roster")
        
        # Remove duplicates
        my_daily_projs = my_daily_projs.drop_duplicates(subset=['Name'])
        
        # If no players found after filtering, return error
        if len(my_daily_projs) == 0:
            return None, None, "No players found in today's projections for your team after filtering"
            
        # Key stat columns to keep - ALT league stats
        stat_cols = []
        for col in ['HR', 'BB', 'SBN', 'OBP', 'SLG', 'AB', 'PA', 'H']:
            if col in my_daily_projs.columns:
                stat_cols.append(col)
                
        # Calculate Z-scores and MASH - using ALT functions
        top_n = 100  # Daily top players for reference
        my_daily_projs = calculate_zscores_hitters_alt(my_daily_projs, daily_hitters, top_n=top_n)
        
        # Find z-score columns
        z_cols = [col for col in my_daily_projs.columns if col.endswith('_z')]
        
        # Add MASH if we have category weights
        category_weights = None
        if standings_file and my_team:
            try:
                category_weights = analyze_standings(standings_file, my_team)
                my_daily_projs = calculate_mash_score_alt(my_daily_projs, category_weights, is_pitcher=False)
            except Exception as e:
                print(f"Error calculating MASH: {str(e)}")
        
        # If we don't have MASH scores, use Total_Z
        score_col = 'MASH' if 'MASH' in my_daily_projs.columns else 'Total_Z'
        if score_col not in my_daily_projs.columns:
            return None, None, "No optimization score column found"
        
        # Sort by optimization score
        my_daily_projs = my_daily_projs.sort_values(score_col, ascending=False)
        
        # Define positions and their priorities (same as standard league)
        position_order = ['C', 'C', '1B', '2B', '3B', 'SS', 'CI', 'MI', 'OF', 'OF', 'OF', 'OF', 'OF', 'UTIL']
        position_map = {
            'C': ['C'],
            '1B': ['1B'],
            '2B': ['2B'],
            '3B': ['3B'],
            'SS': ['SS'],
            'CI': ['1B', '3B'],
            'MI': ['2B', 'SS'],
            'OF': ['OF', 'LF', 'CF', 'RF'],
            'UTIL': ['C', '1B', '2B', '3B', 'SS', 'OF', 'DH', 'UTIL', 'UT', 'LF', 'CF', 'RF']
        }
        
        # Function to gather player stats for the final dataframe
        def create_player_entry(player, position):
            entry = {
                'Position': position,
                'Name': player['Name'] if 'Name' in player else 'EMPTY',
                'Positions': player['Positions'] if 'Positions' in player else '',
                score_col: player[score_col] if score_col in player else 0,
                'Team': player['Team'] if 'Team' in player else ''
            }
            
            # Add the projected stats
            for col in stat_cols:
                if col in player:
                    entry[col] = player[col]
                    
            # Add the z-scores
            for col in z_cols:
                if col in player:
                    entry[col] = player[col]
                    
            return entry
        
        # Optimize lineup
        lineup = []
        bench = []
        used_players = set()
        
        # First pass - fill positions in order
        for pos in position_order:
            eligible_players = []
            for _, player in my_daily_projs.iterrows():
                if player['Name'] in used_players:
                    continue
                
                if 'Positions' in player and player['Positions']:
                    player_positions = str(player['Positions']).upper().split('/')
                    # Check if player can play this position
                    is_eligible = False
                    for valid_pos in position_map[pos]:
                        if any(valid_pos in p for p in player_positions):
                            is_eligible = True
                            break
                    
                    if is_eligible:
                        eligible_players.append(player)
            
            # If we found eligible players, use the one with highest MASH
            if eligible_players:
                best_player = max(eligible_players, key=lambda x: x[score_col])
                lineup.append(create_player_entry(best_player, pos))
                used_players.add(best_player['Name'])
            else:
                # Add EMPTY entry when no player is available
                lineup.append({'Position': pos, 'Name': 'EMPTY', 'Positions': '', score_col: 0, 'Team': ''})
        
        # Second pass - put remaining players on bench
        for _, player in my_daily_projs.iterrows():
            if player['Name'] not in used_players:
                bench.append(create_player_entry(player, 'Bench'))
        
        # Sort bench by score (highest to lowest)
        bench = sorted(bench, key=lambda x: x[score_col], reverse=True)
        
        # Create the output DataFrame
        lineup_df = pd.DataFrame(lineup)
        bench_df = pd.DataFrame(bench)
        
        # Combine lineup and bench
        full_roster = pd.concat([lineup_df, bench_df]).reset_index(drop=True)
        
        # Round numeric columns in the display dataframe
        for col in full_roster.select_dtypes(include=[np.number]).columns:
            if col in ['AVG', 'OBP', 'SLG', 'OPS']:
                full_roster[col] = full_roster[col].round(3)
            elif col.endswith('_z') or col == 'MASH' or col == 'Total_Z':
                full_roster[col] = full_roster[col].round(2)
            else:
                full_roster[col] = full_roster[col].round(1)
        
        # Calculate total MASH for the lineup
        lineup_total = (lineup_df[score_col].sum() if score_col in lineup_df.columns 
                        and len(lineup_df) > 0 else 0)
        
        # Create download file
        file_path = os.path.join(temp_dir, "optimized_lineup_alt.csv")
        full_roster.to_csv(file_path, index=False)
        
        # Add a message at the bottom with the total
        status_msg = f"Optimized ALT league lineup total {score_col}: {lineup_total:.2f}"
        
        return full_roster, file_path, status_msg
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"Error details: {error_details}")
        return None, None, f"Error optimizing lineup: {str(e)}"

# Create a simpler interface with clearer tabs
with gr.Blocks() as demo:
    gr.Markdown("# Fantasy Baseball AFRO/FA Player Finder")
    
    with gr.Tabs():
        with gr.Tab("Standard League (AVG/R/HR/RBI/SB/OPS)"):
            with gr.Tabs():
                with gr.Tab("ROS Projections"):
                    gr.Markdown("Upload your latest league file to find AFRO and Free Agent (FA) players from ROS projections.")
                    with gr.Row():
                        ros_league_file = gr.File(label="Upload Fantrax League File")
                    with gr.Row():
                        ros_standings_file = gr.File(label="Upload Standings File (Optional for MASH)")
                        ros_team_name = gr.Textbox(label="Your Team Name (Required for MASH)")
                    with gr.Row():
                        ros_run_button = gr.Button("Generate ROS Reports")
                    
                    ros_status = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Tabs():
                        with gr.Tab("AFRO Hitters"):
                            afro_hitters_table = gr.Dataframe(label="AFRO Hitters", interactive=False)
                        with gr.Tab("FA Hitters"):
                            fa_hitters_table = gr.Dataframe(label="FA Hitters", interactive=False)
                        with gr.Tab("AFRO Pitchers"):
                            afro_pitchers_table = gr.Dataframe(label="AFRO Pitchers", interactive=False)
                        with gr.Tab("FA Pitchers"):
                            fa_pitchers_table = gr.Dataframe(label="FA Pitchers", interactive=False)
                    
                    with gr.Row():
                        ros_download = gr.File(label="Download CSV Files")
                
                with gr.Tab("Daily Projections"):
                    gr.Markdown("Upload your league file and today's daily projections to find available players.")
                    with gr.Row():
                        daily_league_file = gr.File(label="Upload Fantrax League File")
                    with gr.Row():
                        daily_hitters_file = gr.File(label="Upload Razzball Daily Hitters")
                        daily_pitchers_file = gr.File(label="Upload Razzball Daily Pitchers")
                    with gr.Row():
                        daily_standings_file = gr.File(label="Upload Standings File (Optional for MASH)")
                        daily_team_name = gr.Textbox(label="Your Team Name (Required for MASH)")
                    with gr.Row():
                        daily_run_button = gr.Button("Generate Daily Reports")
                    
                    daily_status = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Tabs():
                        with gr.Tab("AFRO Hitters"):
                            daily_afro_hitters_table = gr.Dataframe(label="AFRO Hitters", interactive=False)
                        with gr.Tab("FA Hitters"):
                            daily_fa_hitters_table = gr.Dataframe(label="FA Hitters", interactive=False)
                        with gr.Tab("AFRO Pitchers"):
                            daily_afro_pitchers_table = gr.Dataframe(label="AFRO Pitchers", interactive=False)
                        with gr.Tab("FA Pitchers"):
                            daily_fa_pitchers_table = gr.Dataframe(label="FA Pitchers", interactive=False)
                    
                    with gr.Row():
                        daily_download = gr.File(label="Download CSV Files")
                
                with gr.Tab("Optimized Lineup"):
                    gr.Markdown("Create an optimized daily lineup based on MASH scores.")
                    with gr.Row():
                        lineup_league_file = gr.File(label="Upload Fantrax League File")
                        lineup_hitters_file = gr.File(label="Upload Razzball Daily Hitters")
                    with gr.Row():
                        lineup_standings_file = gr.File(label="Upload Standings File (Required for MASH)")
                        lineup_team_name = gr.Textbox(label="Your Team Name")
                    with gr.Row():
                        lineup_run_button = gr.Button("Generate Optimized Lineup")
                        
                    lineup_status = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Row():
                        lineup_table = gr.Dataframe(label="Optimized Lineup", interactive=False)
                    
                    with gr.Row():
                        lineup_download = gr.File(label="Download Lineup CSV")

        with gr.Tab("Alt League (HR/BB/SBN/OBP/SLG)"):
            with gr.Tabs():
                with gr.Tab("ROS Projections"):
                    gr.Markdown("Upload your latest league file to find AFRO and Free Agent (FA) players from ROS projections.")
                    with gr.Row():
                        ros_league_file_alt = gr.File(label="Upload Fantrax League File")
                    with gr.Row():
                        ros_standings_file_alt = gr.File(label="Upload Standings File (Optional for MASH)")
                        ros_team_name_alt = gr.Textbox(label="Your Team Name (Required for MASH)")
                    with gr.Row():
                        ros_run_button_alt = gr.Button("Generate ROS Reports (Alt League)")
                    
                    ros_status_alt = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Tabs():
                        with gr.Tab("AFRO Hitters"):
                            afro_hitters_table_alt = gr.Dataframe(label="AFRO Hitters", interactive=False)
                        with gr.Tab("FA Hitters"):
                            fa_hitters_table_alt = gr.Dataframe(label="FA Hitters", interactive=False)
                        with gr.Tab("AFRO Pitchers"):
                            afro_pitchers_table_alt = gr.Dataframe(label="AFRO Pitchers", interactive=False)
                        with gr.Tab("FA Pitchers"):
                            fa_pitchers_table_alt = gr.Dataframe(label="FA Pitchers", interactive=False)
                    
                    with gr.Row():
                        ros_download_alt = gr.File(label="Download CSV Files")
                
                with gr.Tab("Daily Projections"):
                    gr.Markdown("Upload your league file and today's daily projections to find available players.")
                    with gr.Row():
                        daily_league_file_alt = gr.File(label="Upload Fantrax League File")
                    with gr.Row():
                        daily_hitters_file_alt = gr.File(label="Upload Razzball Daily Hitters")
                        daily_pitchers_file_alt = gr.File(label="Upload Razzball Daily Pitchers")
                    with gr.Row():
                        daily_standings_file_alt = gr.File(label="Upload Standings File (Optional for MASH)")
                        daily_team_name_alt = gr.Textbox(label="Your Team Name (Required for MASH)")
                    with gr.Row():
                        daily_run_button_alt = gr.Button("Generate Daily Reports (Alt League)")
                    
                    daily_status_alt = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Tabs():
                        with gr.Tab("AFRO Hitters"):
                            daily_afro_hitters_table_alt = gr.Dataframe(label="AFRO Hitters", interactive=False)
                        with gr.Tab("FA Hitters"):
                            daily_fa_hitters_table_alt = gr.Dataframe(label="FA Hitters", interactive=False)
                        with gr.Tab("AFRO Pitchers"):
                            daily_afro_pitchers_table_alt = gr.Dataframe(label="AFRO Pitchers", interactive=False)
                        with gr.Tab("FA Pitchers"):
                            daily_fa_pitchers_table_alt = gr.Dataframe(label="FA Pitchers", interactive=False)
                    
                    with gr.Row():
                        daily_download_alt = gr.File(label="Download CSV Files")
                
                with gr.Tab("Optimized Lineup"):
                    gr.Markdown("Create an optimized daily lineup based on MASH scores.")
                    with gr.Row():
                        lineup_league_file_alt = gr.File(label="Upload Fantrax League File")
                        lineup_hitters_file_alt = gr.File(label="Upload Razzball Daily Hitters")
                    with gr.Row():
                        lineup_standings_file_alt = gr.File(label="Upload Standings File (Required for MASH)")
                        lineup_team_name_alt = gr.Textbox(label="Your Team Name")
                    with gr.Row():
                        lineup_run_button_alt = gr.Button("Generate Optimized Lineup (Alt League)")
                        
                    lineup_status_alt = gr.Textbox(label="Status", interactive=False)
                    
                    with gr.Row():
                        lineup_table_alt = gr.Dataframe(label="Optimized Lineup", interactive=False)
                    
                    with gr.Row():
                        lineup_download_alt = gr.File(label="Download Lineup CSV")
    
    # Standard League connections
    ros_run_button.click(
        fn=filter_and_export_ros,
        inputs=[ros_league_file, ros_standings_file, ros_team_name],
        outputs=[afro_hitters_table, fa_hitters_table, afro_pitchers_table, fa_pitchers_table, ros_download, ros_status]
    )

    daily_run_button.click(
        fn=filter_and_export_daily,
        inputs=[daily_league_file, daily_hitters_file, daily_pitchers_file, daily_standings_file, daily_team_name],
        outputs=[daily_afro_hitters_table, daily_fa_hitters_table, daily_afro_pitchers_table, daily_fa_pitchers_table, daily_download, daily_status]
    )
    
    lineup_run_button.click(
        fn=optimize_daily_lineup,
        inputs=[lineup_hitters_file, lineup_league_file, lineup_standings_file, lineup_team_name],
        outputs=[lineup_table, lineup_download, lineup_status]
    )

    # Alt League connections
    ros_run_button_alt.click(
        fn=filter_and_export_ros_alt,
        inputs=[ros_league_file_alt, ros_standings_file_alt, ros_team_name_alt],
        outputs=[afro_hitters_table_alt, fa_hitters_table_alt, afro_pitchers_table_alt, fa_pitchers_table_alt, ros_download_alt, ros_status_alt]
    )

    daily_run_button_alt.click(
        fn=filter_and_export_daily_alt,
        inputs=[daily_league_file_alt, daily_hitters_file_alt, daily_pitchers_file_alt, daily_standings_file_alt, daily_team_name_alt],
        outputs=[daily_afro_hitters_table_alt, daily_fa_hitters_table_alt, daily_afro_pitchers_table_alt, daily_fa_pitchers_table_alt, daily_download_alt, daily_status_alt]
    )
    
    lineup_run_button_alt.click(
        fn=optimize_daily_lineup_alt,
        inputs=[lineup_hitters_file_alt, lineup_league_file_alt, lineup_standings_file_alt, lineup_team_name_alt],
        outputs=[lineup_table_alt, lineup_download_alt, lineup_status_alt]
    )

if __name__ == "__main__":
    demo.launch()
